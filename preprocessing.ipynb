{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline\n",
    "\n",
    "plus, bonus Naive Bayes Model at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from datetime import datetime\n",
    "dateparse = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S %z %Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"Ethan's EDA/scraped_comments.csv\", parse_dates=['date'], date_parser=dateparse).sample(n=50000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.drop_duplicates(subset=\"comment_id\", keep=\"first\", inplace=True)\n",
    "\n",
    "# TODO: move dropped rows into another CSV file and \n",
    "\n",
    "reviews.dropna(subset=[\"comment\"], inplace=True)\n",
    "# drop rows containing only \"No Comments\" (default value assigned by RMP to a review that didn't enter a comment)\n",
    "reviews = reviews[reviews[\"comment\"] != \"No Comments\"]\n",
    "# replace all comments with less than 5 words with a NaN\n",
    "reviews[\"comment\"] = reviews[\"comment\"].apply(lambda x: x if len(x.split()) > 5 else None)\n",
    "# drop rows containing NaN comment\n",
    "reviews.dropna(subset=[\"comment\"], inplace=True)\n",
    "\n",
    "reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_proper = []\n",
    "\n",
    "for i in range(reviews.shape[0]):\n",
    "    review = reviews[\"comment\"][i]\n",
    "    review = re.sub('&([a-zA-z]+|#\\d+);', \"\", review)           # remove HTML codes\n",
    "    review = re.sub('&#63;?', '', review)                       # HTML code for question mark evades erasure on occasion, handle here\n",
    "    review = re.sub(r'\\s*https?://\\S+(\\s+|$)', ' ', review)                                     # remove links\n",
    "    review = re.sub(\"^(\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}$\", ' ', review)         # remove phone numbers\n",
    "    review = re.sub(\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", \" \", review)              # remove email addresses\n",
    "    \n",
    "    review = re.sub('\\d{4,}', ' ', review)                      # keep numbers between 1 and 3 digits\n",
    "    review = re.sub('[^a-zA-Z\\s\\d]+', ' ', review)              # remove non-alphabetic characters, spaces, and any remaining digits\n",
    "\n",
    "    review = re.sub(r'(.)\\1\\1+', '\\g<1>', review)               # replace any three characters in a row with one\n",
    "    \n",
    "    review = re.sub('\\s+', ' ', review)\n",
    "    review = review.lower()                                     # lowercase review for uniformity\n",
    "    comments_proper.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amend list of stop words to keep whatever it is we want by removing words from list that we want to keep\n",
    "\n",
    "# TODO: is the list of stopwords on git complete and accurate or does someone want to read through all 325 stopwords spacy gives and determine which ones to keep?\n",
    "stopwords = STOP_WORDS\n",
    "stopwords.remove(\"but\")\n",
    "stopwords.remove(\"not\")\n",
    "stopwords.remove(\"nor\")\n",
    "stopwords.remove(\"never\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "def lemmatize_pipe(doc):\n",
    "    lemma_list = [str(tok.lemma_).lower() for tok in doc if tok.is_alpha and tok.text.lower() not in stopwords]\n",
    "    return lemma_list\n",
    "\n",
    "def preprocess_pipe(texts):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=20):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe\n",
    "\n",
    "no_stopwords = preprocess_pipe(reviews[\"comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>comment</th>\n",
       "      <th>clarityRating</th>\n",
       "      <th>cleanedComment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keith</td>\n",
       "      <td>Halladay</td>\n",
       "      <td>Keith is the best. Not afraid to give his hone...</td>\n",
       "      <td>5</td>\n",
       "      <td>keith good afraid honest opinion grading paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>Lankau</td>\n",
       "      <td>Lankau was great for 4000 and 5110. He makes c...</td>\n",
       "      <td>4</td>\n",
       "      <td>lankau great make class fun hilarious prepared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "      <td>McGivern</td>\n",
       "      <td>I hated every second of my life that I had to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>hate second life sit class intelligent man but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Howard G.</td>\n",
       "      <td>Tucker</td>\n",
       "      <td>Crazy Man. No grading system. You dont know yo...</td>\n",
       "      <td>5</td>\n",
       "      <td>crazy man grading system not know grade tell s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul</td>\n",
       "      <td>Cohen</td>\n",
       "      <td>This teacher is the worst I've ever taken in m...</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher bad take entire schooling career rude ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstName  lastName                                            comment  \\\n",
       "0      Keith  Halladay  Keith is the best. Not afraid to give his hone...   \n",
       "1    Charles    Lankau  Lankau was great for 4000 and 5110. He makes c...   \n",
       "2      James  McGivern  I hated every second of my life that I had to ...   \n",
       "3  Howard G.    Tucker  Crazy Man. No grading system. You dont know yo...   \n",
       "4       Paul     Cohen  This teacher is the worst I've ever taken in m...   \n",
       "\n",
       "   clarityRating                                     cleanedComment  \n",
       "0              5  keith good afraid honest opinion grading paper...  \n",
       "1              4  lankau great make class fun hilarious prepared...  \n",
       "2              2  hate second life sit class intelligent man but...  \n",
       "3              5  crazy man grading system not know grade tell s...  \n",
       "4              1  teacher bad take entire schooling career rude ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews.loc[:, [\"firstName\", \"lastName\", \"comment\", \"clarityRating\"]]\n",
    "reviews[\"cleanedComment\"] = pd.Series([\" \".join(comm) for comm in no_stopwords])\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>comment</th>\n",
       "      <th>clarityRating</th>\n",
       "      <th>cleanedComment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keith</td>\n",
       "      <td>Halladay</td>\n",
       "      <td>Keith is the best. Not afraid to give his hone...</td>\n",
       "      <td>5</td>\n",
       "      <td>keith good afraid honest opinion grading paper...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>Lankau</td>\n",
       "      <td>Lankau was great for 4000 and 5110. He makes c...</td>\n",
       "      <td>4</td>\n",
       "      <td>lankau great make class fun hilarious prepared...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "      <td>McGivern</td>\n",
       "      <td>I hated every second of my life that I had to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>hate second life sit class intelligent man but...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Howard G.</td>\n",
       "      <td>Tucker</td>\n",
       "      <td>Crazy Man. No grading system. You dont know yo...</td>\n",
       "      <td>5</td>\n",
       "      <td>crazy man grading system not know grade tell s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul</td>\n",
       "      <td>Cohen</td>\n",
       "      <td>This teacher is the worst I've ever taken in m...</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher bad take entire schooling career rude ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstName  lastName                                            comment  \\\n",
       "0      Keith  Halladay  Keith is the best. Not afraid to give his hone...   \n",
       "1    Charles    Lankau  Lankau was great for 4000 and 5110. He makes c...   \n",
       "2      James  McGivern  I hated every second of my life that I had to ...   \n",
       "3  Howard G.    Tucker  Crazy Man. No grading system. You dont know yo...   \n",
       "4       Paul     Cohen  This teacher is the worst I've ever taken in m...   \n",
       "\n",
       "   clarityRating                                     cleanedComment  sentiment  \n",
       "0              5  keith good afraid honest opinion grading paper...          1  \n",
       "1              4  lankau great make class fun hilarious prepared...          1  \n",
       "2              2  hate second life sit class intelligent man but...         -1  \n",
       "3              5  crazy man grading system not know grade tell s...          1  \n",
       "4              1  teacher bad take entire schooling career rude ...         -1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"sentiment\"] = reviews[\"clarityRating\"].apply(lambda x: 1 if x > 3 else 0 if x == 3 else -1)       # accuracy: 0.7518830305715551 for 50000 comments\n",
    "#reviews[\"sentiment\"] = reviews[\"clarityRating\"].apply(lambda x: 1 if x > 2.5 else 0)                        # accuracy: 0.8635356668143553 for 50000 comments\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing cleaned comments to a new csv file so we (hopefully) don't have to run this everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews.to_csv(\"comments_preproc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=2500)\n",
    "X = cv.fit_transform(comments_proper).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(reviews.loc[:, [\"sentiment\"]])     # isolate sentiments\n",
    "y = y.loc[:, \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_valid = X[0:20000]\n",
    "#y_valid = y[0:20000]\n",
    "\n",
    "#X = X[20000:]\n",
    "#y = y[20000:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.naive_bayes import BernoulliNB\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "#model = BernoulliNB().fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 72.0425343376163\n",
      "[[1628  302  412]\n",
      " [ 280  376  465]\n",
      " [ 289  776 4500]]\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "conf_m = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy Score: \" + str(acc_score * 100))\n",
    "print(conf_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Matrix read like:*\n",
    "\n",
    "* __Top left:__ 0s correctly identifed as 0s (*true negative*)\n",
    "* __Top right:__ 0s incorrectly predicted as 1s (*false positive*)\n",
    "* __Bottom left:__ 1s incorrectly predicted as 0s (*false negative*)\n",
    "* __Bottom right:__ 1s correctly identifed as 1s (*true positive*)\n",
    "\n",
    "Can extend to 3x3 case, though more complicated, see https://towardsdatascience.com/understanding-the-confusion-matrix-from-scikit-learn-c51d88929c79 for a better explanation than I can muster :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Precision and Recall of Model\n",
    "\n",
    "See https://en.m.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.8532494758909853; Recall=0.8435233160621761\n"
     ]
    }
   ],
   "source": [
    "# Precision wrt 0\n",
    "prec_0 = conf_m[0][0] / float(conf_m[1][0] + conf_m[0][0])\n",
    "\n",
    "# Recall wrt 0\n",
    "rec_0 = conf_m[0][0] / float(conf_m[0][1] + conf_m[0][0])\n",
    "\n",
    "print(\"Precision={0}; Recall={1}\".format(prec_0,rec_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.5545722713864307; Recall=0.573170731707317\n"
     ]
    }
   ],
   "source": [
    "# Precision wrt 1\n",
    "prec_1 = conf_m[1][1] / float(conf_m[0][1] + conf_m[1][1])\n",
    "\n",
    "# Recall wrt 1\n",
    "rec_1 = conf_m[1][1] / float(conf_m[1][0] + conf_m[1][1])\n",
    "\n",
    "print(\"Precision={0}; Recall={1}\".format(prec_1,rec_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.7402160534550013; Recall=0.720425343376163\n"
     ]
    }
   ],
   "source": [
    "# More refined way to calculate precision and recall, should've done my research first lol\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"Precision={0}; Recall={1}\".format(precision, recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed8ce2715666cca47edfe3dc40f16f58fc193b5a7b06958e2ae06c97afdf9990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
