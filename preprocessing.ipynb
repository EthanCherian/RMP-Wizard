{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline\n",
    "\n",
    "plus, bonus Naive Bayes Model at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import pkg_resources\n",
    "#!pip install symspellpy\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from datetime import datetime\n",
    "dateparse = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S %z %Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"scraped_comments.csv\", parse_dates=['date'], date_parser=dateparse).sample(n=50000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.drop_duplicates(subset=\"comment_id\", keep=\"first\", inplace=True)\n",
    "\n",
    "# TODO: move dropped rows into another CSV file and \n",
    "\n",
    "reviews.dropna(subset=[\"comment\"], inplace=True)\n",
    "# drop rows containing only \"No Comments\" (default value assigned by RMP to a review that didn't enter a comment)\n",
    "reviews = reviews[reviews[\"comment\"] != \"No Comments\"]\n",
    "# replace all comments with less than 5 words with a NaN\n",
    "reviews[\"comment\"] = reviews[\"comment\"].apply(lambda x: x if len(x.split()) > 5 else None)\n",
    "# drop rows containing NaN comment\n",
    "reviews.dropna(subset=[\"comment\"], inplace=True)\n",
    "\n",
    "reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTICONS = {\n",
    "    u\":‑)\":\"emo_pos\",\n",
    "    u\":-))\":\"emo_pos\",\n",
    "    u\":-)))\":\"emo_pos\",\n",
    "    u\":)\":\"emo_pos\",\n",
    "    u\":))\":\"emo_pos\",\n",
    "    u\":)))\":\"emo_pos\",\n",
    "    u\":-]\":\"emo_pos\",\n",
    "    u\":]\":\"emo_pos\",\n",
    "    u\":-3\":\"emo_pos\",\n",
    "    u\":3\":\"emo_pos\",\n",
    "    u\":->\":\"emo_pos\",\n",
    "    u\":>\":\"emo_pos\",\n",
    "    u\"8-)\":\"emo_pos\",\n",
    "    u\":-}\":\"emo_pos\",\n",
    "    u\":}\":\"emo_pos\",\n",
    "    u\":-)\":\"emo_pos\",\n",
    "    u\":c)\":\"emo_pos\",\n",
    "    u\":^)\":\"emo_pos\",\n",
    "    u\"=]\":\"emo_pos\",\n",
    "    u\"=)\":\"emo_pos\",\n",
    "    u\":‑D\":\"emo_pos\",\n",
    "    u\":D\":\"emo_pos\",\n",
    "    u\"8‑D\":\"emo_pos\",\n",
    "    u\"8D\":\"emo_pos\",\n",
    "    u\"X‑D\":\"emo_pos\",\n",
    "    u\"XD\":\"emo_pos\",\n",
    "    u\"=D\":\"emo_pos\",\n",
    "    u\"=3\":\"emo_pos\",\n",
    "    u\"B^D\":\"emo_pos\",\n",
    "    u\":-))\":\"emo_pos\",\n",
    "    u\":-(\":\"emo_neg\",\n",
    "    u\":‑(\":\"emo_neg\",\n",
    "    u\":(\":\"emo_neg\",\n",
    "    u\":‑c\":\"emo_neg\",\n",
    "    u\":c\":\"emo_neg\",\n",
    "    u\":‑<\":\"emo_neg\",\n",
    "    u\":<\":\"emo_neg\",\n",
    "    u\":‑[\":\"emo_neg\",\n",
    "    u\":[\":\"emo_neg\",\n",
    "    u\":-||\":\"emo_neg\",\n",
    "    u\">:[\":\"emo_neg\",\n",
    "    u\":{\":\"emo_neg\",\n",
    "    u\":@\":\"emo_neg\",\n",
    "    u\">:(\":\"emo_neg\",\n",
    "    u\":'‑(\":\"emo_neg\",\n",
    "    u\":'(\":\"emo_neg\",\n",
    "    u\":'‑)\":\"emo_pos\",\n",
    "    u\":')\":\"emo_pos\",\n",
    "    u\"D‑':\":\"emo_neg\",\n",
    "    u\"D:<\":\"emo_neg\",\n",
    "    u\"D:\":\"emo_neg\",\n",
    "    u\"D8\":\"emo_neg\",\n",
    "    u\"D;\":\"emo_neg\",\n",
    "    u\"D=\":\"emo_neg\",\n",
    "    u\"DX\":\"emo_neg\",\n",
    "    u\";‑)\":\"emo_pos\",\n",
    "    u\";)\":\"emo_pos\",\n",
    "    u\"*-)\":\"emo_pos\",\n",
    "    u\"*)\":\"emo_pos\",\n",
    "    u\";‑]\":\"emo_pos\",\n",
    "    u\";]\":\"emo_pos\",\n",
    "    u\";^)\":\"emo_pos\",\n",
    "    u\":‑,\":\"emo_pos\",\n",
    "    u\";D\":\"emo_pos\",\n",
    "    u\":‑P\":\"emo_pos\",\n",
    "    u\":P\":\"emo_pos\",\n",
    "    u\"X‑P\":\"emo_pos\",\n",
    "    u\"XP\":\"emo_pos\",\n",
    "    u\":‑Þ\":\"emo_pos\",\n",
    "    u\":Þ\":\"emo_pos\",\n",
    "    u\"=p\":\"emo_pos\",\n",
    "    u\":‑/\":\"emo_neg\",\n",
    "    u\":/\":\"emo_neg\",\n",
    "    u\":-[.]\":\"emo_neg\",\n",
    "    u\">:[(\\)]\":\"emo_neg\",\n",
    "    u\">:/\":\"emo_neg\",\n",
    "    u\":[(\\)]\":\"emo_neg\",\n",
    "    u\"=/\":\"emo_neg\",\n",
    "    u\"=[(\\)]\":\"emo_neg\",\n",
    "    u\":L\":\"emo_neg\",\n",
    "    u\"=L\":\"emo_neg\",\n",
    "    u\":‑|\":\"emo_neg\",\n",
    "    u\":|\":\"emo_neg\",\n",
    "    u\"O:‑)\":\"emo_pos\",\n",
    "    u\"O:)\":\"emo_pos\",\n",
    "    u\"0:‑3\":\"emo_pos\",\n",
    "    u\"0:3\":\"emo_pos\",\n",
    "    u\"0:‑)\":\"emo_pos\",\n",
    "    u\"0:)\":\"emo_pos\",\n",
    "    u\":‑b\":\"emo_pos\",\n",
    "    u\"(>_<)\":\"emo_neg\",\n",
    "    u\"(>_<)>\":\"emo_neg\",\n",
    "    u\"^_^\":\"emo_pos\",\n",
    "    u\"(^_^)/\":\"emo_pos\",\n",
    "    u\"(^O^)／\":\"emo_pos\",\n",
    "    u\"(^o^)／\":\"emo_pos\",\n",
    "    u\"('_')\":\"emo_neg\",\n",
    "    u\"(/_;)\":\"emo_neg\",\n",
    "    u\"(T_T) (;_;)\":\"emo_neg\",\n",
    "    u\"(;_;\":\"emo_neg\",\n",
    "    u\"(;_:)\":\"emo_neg\",\n",
    "    u\"(;O;)\":\"emo_neg\",\n",
    "    u\"(:_;)\":\"emo_neg\",\n",
    "    u\"(ToT)\":\"emo_neg\",\n",
    "    u\";_;\":\"emo_neg\",\n",
    "    u\";-;\":\"emo_neg\",\n",
    "    u\";n;\":\"emo_neg\",\n",
    "    u\"Q.Q\":\"emo_neg\",\n",
    "    u\"T.T\":\"emo_neg\",\n",
    "    u\"Q_Q\":\"emo_neg\",\n",
    "    u\"(-.-)\":\"emo_pos\",\n",
    "    u\"(-_-)\":\"emo_pos\",\n",
    "    u\"(；一_一)\":\"emo_pos\",\n",
    "    u\"(=_=)\":\"emo_neg\",\n",
    "    u\"^m^\":\"emo_pog\",\n",
    "    u\">^_^<\":\"emo_pos\",\n",
    "    u\"<^!^>\":\"emo_pos\",\n",
    "    u\"^/^\":\"emo_pos\",\n",
    "    u\"（*^_^*）\" :\"emo_pos\",\n",
    "    u\"(^<^) (^.^)\":\"emo_pos\",\n",
    "    u\"(^^)\":\"emo_pos\",\n",
    "    u\"(^.^)\":\"emo_pos\",\n",
    "    u\"(^_^.)\":\"emo_pos\",\n",
    "    u\"(^_^)\":\"emo_pos\",\n",
    "    u\"(^^)\":\"emo_pos\",\n",
    "    u\"(^J^)\":\"emo_pos\",\n",
    "    u\"(*^.^*)\":\"emo_pos\",\n",
    "    u\"(^—^）\":\"emo_pos\",\n",
    "    u\"(#^.^#)\":\"emo_pos\",\n",
    "    u\"(*^0^*)\":\"emo_pos\",\n",
    "    u\"(*^^)v\":\"emo_pos\",\n",
    "    u\"(^_^)v\":\"emo_pos\",\n",
    "    u'(-\"-)':\"emo_neg\",\n",
    "    u\"(ーー;)\":\"emo_neg\",\n",
    "    u\"(＾ｖ＾)\":\"emo_pos\",\n",
    "    u\"(＾ｕ＾)\":\"emo_pos\",\n",
    "    u\"(^)o(^)\":\"emo_pos\",\n",
    "    u\"(^O^)\":\"emo_pos\",\n",
    "    u\"(^o^)\":\"emo_pos\",\n",
    "    u\")^o^(\":\"emo_pos\",\n",
    "    u\":O o_O\":\"emo_neg\",\n",
    "    u\"o_0\":\"emo_neg\",\n",
    "    u\"o.O\":\"emo_neg\",\n",
    "    u\"(o.o)\":\"emo_neg\",\n",
    "    u\"(*￣m￣)\": \"emo_neg\",\n",
    "}\n",
    "\n",
    "def replace_emoticons(text):\n",
    "    return EMOTICONS.get(text, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\n",
    "    \"ain't\": \"is not\", \n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"'cause\": \"because\", \n",
    "    \"could've\": \"could have\", \n",
    "    \"couldn't\": \"could not\", \n",
    "    \"didn't\": \"did not\",  \n",
    "    \"doesn't\": \"does not\", \n",
    "    \"don't\": \"do not\", \n",
    "    \"hadn't\": \"had not\", \n",
    "    \"hasn't\": \"has not\", \n",
    "    \"haven't\": \"have not\", \n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\", \n",
    "    \"he's\": \"he is\", \n",
    "    \"how'd\": \"how did\", \n",
    "    \"how'd'y\": \"how do you\", \n",
    "    \"how'll\": \"how will\", \n",
    "    \"how's\": \"how is\",  \n",
    "    \"I'd\": \"I would\", \n",
    "    \"I'd've\": \"I would have\", \n",
    "    \"I'll\": \"I will\", \n",
    "    \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\", \n",
    "    \"I've\": \"I have\", \n",
    "    \"i'd\": \"i would\", \n",
    "    \"i'd've\": \"i would have\", \n",
    "    \"i'll\": \"i will\",  \n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\", \n",
    "    \"i've\": \"i have\", \n",
    "    \"isn't\": \"is not\", \n",
    "    \"it'd\": \"it would\", \n",
    "    \"it'd've\": \"it would have\", \n",
    "    \"it'll\": \"it will\", \n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\", \n",
    "    \"let's\": \"let us\", \n",
    "    \"ma'am\": \"madam\", \n",
    "    \"mayn't\": \"may not\", \n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\", \n",
    "    \"must've\": \"must have\", \n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\"}\n",
    "\n",
    "def expand_contraction(text): # Before expanding contraction, might want to clean of symbols that are not '\n",
    "  return contraction_mapping.get(text, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spell Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
    ")\n",
    "# term_index is the column of the term and count_index is the\n",
    "# column of the term frequency\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "# lookup suggestions for single-word input strings\n",
    "#input_term = \"memebers\"  # misspelling of \"members\"\n",
    "\n",
    "# Verbosity.TOP gets the best suggestion\n",
    "#suggestion = sym_spell.lookup(input_term, Verbosity.TOP, max_edit_distance=2)\n",
    "#print(suggestion[0], len(suggestion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amend list of stop words to keep whatever it is we want by removing words from list that we want to keep\n",
    "\n",
    "# TODO: is the list of stopwords on git complete and accurate or does someone want to read through all 325 stopwords spacy gives and determine which ones to keep?\n",
    "stopwords = STOP_WORDS\n",
    "stopwords.remove(\"but\")\n",
    "stopwords.remove(\"not\")\n",
    "stopwords.remove(\"nor\")\n",
    "stopwords.remove(\"never\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_proper = []\n",
    "#spellchecked_comments = []\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "for i in range(reviews.shape[0]):\n",
    "    review = reviews[\"comment\"][i]\n",
    "    review = re.sub('&([a-zA-z]+|#\\d+);', \"\", review)           # remove HTML codes\n",
    "    review = re.sub('&#63;?', '', review)                       # HTML code for question mark evades erasure on occasion, handle here\n",
    "    review = re.sub(r'\\s*https?://\\S+(\\s+|$)', ' ', review)                                     # remove links\n",
    "    review = re.sub(\"^(\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}$\", ' ', review)         # remove phone numbers\n",
    "    review = re.sub(\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", \" \", review)              # remove email addresses\n",
    "\n",
    "    review_split = review.split()\n",
    "    for i, text in enumerate(review_split):\n",
    "        text = replace_emoticons(text)\n",
    "        text = text.lower()\n",
    "        text = expand_contraction(text)\n",
    "        review_split[i] = text\n",
    "    review = \" \".join(review_split)\n",
    "    \n",
    "    #review = re.sub('\\d{4,}', ' ', review)                      # keep numbers between 1 and 3 digits\n",
    "    review = re.sub('[^a-zA-Z\\s_]+', ' ', review)              # remove non-alphabetic characters, spaces, and any remaining digits\n",
    "\n",
    "    review = re.sub(r'(.)\\1\\1+', '\\g<1>', review)               # replace any three characters in a row with one\n",
    "    \n",
    "    review = re.sub('\\s+', ' ', review)\n",
    "    review = review.lower()                                     # lowercase review for uniformity\n",
    "\n",
    "    review = review.split()\n",
    "    review = [lemm.lemmatize(word) for word in review if word not in stopwords]\n",
    "    review = \" \".join(review)\n",
    "\n",
    "    comments_proper.append(review)\n",
    "    #spellchecked_comments.append(' '.join(sym_spell.lookup(word, Verbosity.TOP, max_edit_distance=2, include_unknown=True)[0].term for word in review.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=[\"parser\", \"ner\", \"textcat\"])\n",
    "\n",
    "def lemmatize_pipe(doc):\n",
    "    lemma_list = [str(tok.lemma_).lower() for tok in doc if tok.is_alpha and tok.text.lower() not in stopwords]\n",
    "    return lemma_list\n",
    "\n",
    "def preprocess_pipe(texts):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=20):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    return preproc_pipe\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stopwords = comments_proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>comment</th>\n",
       "      <th>clarityRating</th>\n",
       "      <th>cleanedComment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keith</td>\n",
       "      <td>Halladay</td>\n",
       "      <td>Keith is the best. Not afraid to give his hone...</td>\n",
       "      <td>5</td>\n",
       "      <td>k e i t h   b e s t   n o t   a f r a i d   h ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>Lankau</td>\n",
       "      <td>Lankau was great for 4000 and 5110. He makes c...</td>\n",
       "      <td>4</td>\n",
       "      <td>l a n k a u   g r e a t   m a k e   c l a s s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "      <td>McGivern</td>\n",
       "      <td>I hated every second of my life that I had to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>h a t e d   s e c o n d   l i f e   s i t   c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Howard G.</td>\n",
       "      <td>Tucker</td>\n",
       "      <td>Crazy Man. No grading system. You dont know yo...</td>\n",
       "      <td>5</td>\n",
       "      <td>c r a z y   m a n   g r a d i n g   s y s t e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul</td>\n",
       "      <td>Cohen</td>\n",
       "      <td>This teacher is the worst I've ever taken in m...</td>\n",
       "      <td>1</td>\n",
       "      <td>t e a c h e r   w o r s t   t a k e n   e n t ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstName  lastName                                            comment  \\\n",
       "0      Keith  Halladay  Keith is the best. Not afraid to give his hone...   \n",
       "1    Charles    Lankau  Lankau was great for 4000 and 5110. He makes c...   \n",
       "2      James  McGivern  I hated every second of my life that I had to ...   \n",
       "3  Howard G.    Tucker  Crazy Man. No grading system. You dont know yo...   \n",
       "4       Paul     Cohen  This teacher is the worst I've ever taken in m...   \n",
       "\n",
       "   clarityRating                                     cleanedComment  \n",
       "0              5  k e i t h   b e s t   n o t   a f r a i d   h ...  \n",
       "1              4  l a n k a u   g r e a t   m a k e   c l a s s ...  \n",
       "2              2  h a t e d   s e c o n d   l i f e   s i t   c ...  \n",
       "3              5  c r a z y   m a n   g r a d i n g   s y s t e ...  \n",
       "4              1  t e a c h e r   w o r s t   t a k e n   e n t ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews.loc[:, [\"firstName\", \"lastName\", \"comment\", \"clarityRating\"]]\n",
    "reviews[\"cleanedComment\"] = pd.Series([\" \".join(comm) for comm in no_stopwords])\n",
    "#reviews[\"cleanedCommentChecked\"] = pd.Series([\" \".join(comm) for comm in no_stopwords_checked])\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>comment</th>\n",
       "      <th>clarityRating</th>\n",
       "      <th>cleanedComment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keith</td>\n",
       "      <td>Halladay</td>\n",
       "      <td>Keith is the best. Not afraid to give his hone...</td>\n",
       "      <td>5</td>\n",
       "      <td>k e i t h   b e s t   n o t   a f r a i d   h ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charles</td>\n",
       "      <td>Lankau</td>\n",
       "      <td>Lankau was great for 4000 and 5110. He makes c...</td>\n",
       "      <td>4</td>\n",
       "      <td>l a n k a u   g r e a t   m a k e   c l a s s ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "      <td>McGivern</td>\n",
       "      <td>I hated every second of my life that I had to ...</td>\n",
       "      <td>2</td>\n",
       "      <td>h a t e d   s e c o n d   l i f e   s i t   c ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Howard G.</td>\n",
       "      <td>Tucker</td>\n",
       "      <td>Crazy Man. No grading system. You dont know yo...</td>\n",
       "      <td>5</td>\n",
       "      <td>c r a z y   m a n   g r a d i n g   s y s t e ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul</td>\n",
       "      <td>Cohen</td>\n",
       "      <td>This teacher is the worst I've ever taken in m...</td>\n",
       "      <td>1</td>\n",
       "      <td>t e a c h e r   w o r s t   t a k e n   e n t ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firstName  lastName                                            comment  \\\n",
       "0      Keith  Halladay  Keith is the best. Not afraid to give his hone...   \n",
       "1    Charles    Lankau  Lankau was great for 4000 and 5110. He makes c...   \n",
       "2      James  McGivern  I hated every second of my life that I had to ...   \n",
       "3  Howard G.    Tucker  Crazy Man. No grading system. You dont know yo...   \n",
       "4       Paul     Cohen  This teacher is the worst I've ever taken in m...   \n",
       "\n",
       "   clarityRating                                     cleanedComment  sentiment  \n",
       "0              5  k e i t h   b e s t   n o t   a f r a i d   h ...          1  \n",
       "1              4  l a n k a u   g r e a t   m a k e   c l a s s ...          1  \n",
       "2              2  h a t e d   s e c o n d   l i f e   s i t   c ...          0  \n",
       "3              5  c r a z y   m a n   g r a d i n g   s y s t e ...          1  \n",
       "4              1  t e a c h e r   w o r s t   t a k e n   e n t ...          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reviews[\"sentiment\"] = reviews[\"clarityRating\"].apply(lambda x: 1 if x > 3 else 0 if x == 3 else -1)       # accuracy: 0.7518830305715551 for 50000 comments\n",
    "reviews[\"sentiment\"] = reviews[\"clarityRating\"].apply(lambda x: 1 if x > 2.5 else 0)                        # accuracy: 0.8635356668143553 for 50000 comments\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing cleaned comments to a new csv file so we (hopefully) don't have to run this everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(\"comments_preproc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=2500, ngram_range=(1, 1))\n",
    "X = cv.fit_transform(no_stopwords).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(reviews.loc[:, [\"sentiment\"]])     # isolate sentiments\n",
    "y = y.loc[:, \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_valid = X[0:20000]\n",
    "#y_valid = y[0:20000]\n",
    "\n",
    "#X = X[20000:]\n",
    "#y = y[20000:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.naive_bayes import BernoulliNB\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "#model = BernoulliNB().fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 85.87727071333629\n",
      "[[1735  606]\n",
      " [ 669 6018]]\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "conf_m = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy Score: \" + str(acc_score * 100))\n",
    "print(conf_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Matrix read like:*\n",
    "\n",
    "* __Top left:__ 0s correctly identifed as 0s (*true negative*)\n",
    "* __Top right:__ 0s incorrectly predicted as 1s (*false positive*)\n",
    "* __Bottom left:__ 1s incorrectly predicted as 0s (*false negative*)\n",
    "* __Bottom right:__ 1s correctly identifed as 1s (*true positive*)\n",
    "\n",
    "Can extend to 3x3 case, though more complicated, see https://towardsdatascience.com/understanding-the-confusion-matrix-from-scikit-learn-c51d88929c79 for a better explanation than I can muster :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['keith best',\n",
       " 'best not',\n",
       " 'not afraid',\n",
       " 'afraid honest',\n",
       " 'honest opinion',\n",
       " 'opinion grading',\n",
       " 'grading paper',\n",
       " 'paper choosing',\n",
       " 'choosing class',\n",
       " 'class discussion',\n",
       " 'discussion super',\n",
       " 'super laid',\n",
       " 'laid funny',\n",
       " 'funny write',\n",
       " 'write paper',\n",
       " 'paper work',\n",
       " 'work good',\n",
       " 'good lankau',\n",
       " 'lankau great',\n",
       " 'great make',\n",
       " 'make class',\n",
       " 'class fun',\n",
       " 'fun hilarious',\n",
       " 'hilarious prepared',\n",
       " 'prepared study',\n",
       " 'study help',\n",
       " 'help but',\n",
       " 'but not',\n",
       " 'not going',\n",
       " 'going easy',\n",
       " 'easy definitely',\n",
       " 'definitely work',\n",
       " 'work grade',\n",
       " 'grade but',\n",
       " 'but make',\n",
       " 'make worth',\n",
       " 'worth listening',\n",
       " 'listening lecture',\n",
       " 'lecture hated',\n",
       " 'hated second',\n",
       " 'second life',\n",
       " 'life sit',\n",
       " 'sit class',\n",
       " 'class intelligent',\n",
       " 'intelligent man',\n",
       " 'man but',\n",
       " 'but idea',\n",
       " 'idea teach',\n",
       " 'teach crazy',\n",
       " 'crazy man',\n",
       " 'man grading',\n",
       " 'grading system',\n",
       " 'system dont',\n",
       " 'dont know',\n",
       " 'know grade',\n",
       " 'grade tell',\n",
       " 'tell student',\n",
       " 'student access',\n",
       " 'access available',\n",
       " 'available expects',\n",
       " 'expects know',\n",
       " 'know cant',\n",
       " 'cant teach',\n",
       " 'teach lehman',\n",
       " 'lehman shes',\n",
       " 'shes alot',\n",
       " 'alot better',\n",
       " 'better hoter',\n",
       " 'hoter lol',\n",
       " 'lol teacher',\n",
       " 'teacher worst',\n",
       " 'worst taken',\n",
       " 'taken entire',\n",
       " 'entire schooling',\n",
       " 'schooling career',\n",
       " 'career rude',\n",
       " 'rude belittles',\n",
       " 'belittles student',\n",
       " 'student not',\n",
       " 'not teach',\n",
       " 'teach test',\n",
       " 'test put',\n",
       " 'put thing',\n",
       " 'thing test',\n",
       " 'test not',\n",
       " 'not talk',\n",
       " 'talk class',\n",
       " 'class ramble',\n",
       " 'ramble review',\n",
       " 'review help',\n",
       " 'help outside',\n",
       " 'outside class',\n",
       " 'class class',\n",
       " 'class boring',\n",
       " 'boring suck',\n",
       " 'suck job',\n",
       " 'job math',\n",
       " 'math awesome',\n",
       " 'awesome know',\n",
       " 'know willing',\n",
       " 'willing help',\n",
       " 'help mistake',\n",
       " 'mistake taking',\n",
       " 'taking math',\n",
       " 'math recommend',\n",
       " 'recommend taking',\n",
       " 'taking s',\n",
       " 's great',\n",
       " 'great teacher',\n",
       " 'teacher enjoys',\n",
       " 'enjoys best',\n",
       " 'best professor',\n",
       " 'professor interested',\n",
       " 'interested passionate',\n",
       " 'passionate teaching',\n",
       " 'teaching lot',\n",
       " 'lot learn',\n",
       " 'learn not',\n",
       " 'not quality',\n",
       " 'quality teacher',\n",
       " 'teacher but',\n",
       " 'but quality',\n",
       " 'quality human',\n",
       " 'human work',\n",
       " 'work hard',\n",
       " 'hard class',\n",
       " 'class but',\n",
       " 'but want',\n",
       " 'want student',\n",
       " 'student want',\n",
       " 'want easy',\n",
       " 'easy class',\n",
       " 'class prof',\n",
       " 'prof want',\n",
       " 'want learn',\n",
       " 'learn stay',\n",
       " 'stay away',\n",
       " 'away prof',\n",
       " 'prof liked',\n",
       " 'liked talk',\n",
       " 'talk mind',\n",
       " 'mind direction',\n",
       " 'direction hardly',\n",
       " 'hardly educational',\n",
       " 'educational nice',\n",
       " 'nice but',\n",
       " 'but learned',\n",
       " 'learned week',\n",
       " 'week class',\n",
       " 'class learn',\n",
       " 'learn english',\n",
       " 'english kushner',\n",
       " 'kushner s',\n",
       " 's class',\n",
       " 'class class',\n",
       " 'class strict',\n",
       " 'strict wanted',\n",
       " 'wanted student',\n",
       " 'student improve',\n",
       " 'improve skill',\n",
       " 'skill course',\n",
       " 'course not',\n",
       " 'not difficult',\n",
       " 'difficult student',\n",
       " 'student applied',\n",
       " 'applied self',\n",
       " 'self nice',\n",
       " 'nice guy',\n",
       " 'guy smart',\n",
       " 'smart entertaining',\n",
       " 'entertaining usually',\n",
       " 'usually missed',\n",
       " 'missed month',\n",
       " 'month class',\n",
       " 'class astronomy',\n",
       " 'astronomy met',\n",
       " 'met week',\n",
       " 'week class',\n",
       " 'class canceled',\n",
       " 'canceled time',\n",
       " 'time row',\n",
       " 'row gave',\n",
       " 'gave home',\n",
       " 'home test',\n",
       " 'test stuff',\n",
       " 'stuff not',\n",
       " 'not chance',\n",
       " 'chance cover',\n",
       " 'cover got',\n",
       " 'got science',\n",
       " 'science credit',\n",
       " 'credit but',\n",
       " 'but not',\n",
       " 'not impressed',\n",
       " 'impressed regard',\n",
       " 'regard cool',\n",
       " 'cool guy',\n",
       " 'guy sure',\n",
       " 'sure read',\n",
       " 'read completely',\n",
       " 'completely lost',\n",
       " 'lost don',\n",
       " 'don t',\n",
       " 't go',\n",
       " 'go topic',\n",
       " 'topic lot',\n",
       " 'lot tape',\n",
       " 'tape recorder',\n",
       " 'recorder good',\n",
       " 'good idea',\n",
       " 'idea class',\n",
       " 'class personally',\n",
       " 'personally favorite',\n",
       " 'favorite class',\n",
       " 'class but',\n",
       " 'but opinion',\n",
       " 'opinion biggest',\n",
       " 'biggest suggestion',\n",
       " 'suggestion sure',\n",
       " 'sure pay',\n",
       " 'pay attention',\n",
       " 'attention read',\n",
       " 'read read',\n",
       " 'read read',\n",
       " 'read took',\n",
       " 'took blended',\n",
       " 'blended course',\n",
       " 'course tutoring',\n",
       " 'tutoring center',\n",
       " 'center semester',\n",
       " 'semester understand',\n",
       " 'understand material',\n",
       " 'material concept',\n",
       " 'concept class',\n",
       " 'class time',\n",
       " 'time consuming',\n",
       " 'consuming time',\n",
       " 'time taking',\n",
       " 'taking note',\n",
       " 'note understanding',\n",
       " 'understanding concept',\n",
       " 'concept paper',\n",
       " 'paper quiz',\n",
       " 'quiz discussion',\n",
       " 'discussion board',\n",
       " 'board overall',\n",
       " 'overall effort',\n",
       " 'effort pas',\n",
       " 'pas class',\n",
       " 'class best',\n",
       " 'best teacher',\n",
       " 'teacher bloch',\n",
       " 'bloch school',\n",
       " 'school excel',\n",
       " 'excel file',\n",
       " 'file time',\n",
       " 'time problem',\n",
       " 'problem guaranteed',\n",
       " 'guaranteed place',\n",
       " 'place unclear',\n",
       " 'unclear boring',\n",
       " 'boring boring',\n",
       " 'boring boring',\n",
       " 'boring class',\n",
       " 'class got',\n",
       " 'got but',\n",
       " 'but suffered',\n",
       " 'suffered grade',\n",
       " 'grade idea',\n",
       " 'idea supposed',\n",
       " 'supposed class',\n",
       " 'class took',\n",
       " 'took statistic',\n",
       " 'statistic summer',\n",
       " 'summer easy',\n",
       " 'easy dont',\n",
       " 'dont know',\n",
       " 'know talking',\n",
       " 'talking got',\n",
       " 'got like',\n",
       " 'like c',\n",
       " 'c test',\n",
       " 'test d',\n",
       " 'd but',\n",
       " 'but aced',\n",
       " 'aced final',\n",
       " 'final got',\n",
       " 'got basically',\n",
       " 'basically went',\n",
       " 'went stuff',\n",
       " 'stuff book',\n",
       " 'book didnt',\n",
       " 'didnt note',\n",
       " 'note pretty',\n",
       " 'pretty great',\n",
       " 'great laugh',\n",
       " 'laugh joke',\n",
       " 'joke hahaha',\n",
       " 'hahaha amazing',\n",
       " 'amazing terrified',\n",
       " 'terrified beginning',\n",
       " 'beginning semester',\n",
       " 'semester but',\n",
       " 'but ended',\n",
       " 'ended enjoying',\n",
       " 'enjoying happy',\n",
       " 'happy help',\n",
       " 'help not',\n",
       " 'not understand',\n",
       " 'understand definitely',\n",
       " 'definitely great',\n",
       " 'great teacher',\n",
       " 'teacher whip',\n",
       " 'whip legend',\n",
       " 'legend prof',\n",
       " 'prof cushing',\n",
       " 'cushing entertaining',\n",
       " 'entertaining easy',\n",
       " 'easy going',\n",
       " 'going professor',\n",
       " 'professor encountered',\n",
       " 'encountered not',\n",
       " 'not difficult',\n",
       " 'difficult approaching',\n",
       " 'approaching help',\n",
       " 'help lot',\n",
       " 'lot participation',\n",
       " 'participation help',\n",
       " 'help actually',\n",
       " 'actually reading',\n",
       " 'reading paper',\n",
       " 'paper home',\n",
       " 'home midterm',\n",
       " 'midterm home',\n",
       " 'home final',\n",
       " 'final math',\n",
       " 'math work',\n",
       " 'work load',\n",
       " 'load not',\n",
       " 'not bad',\n",
       " 'bad plus',\n",
       " 'plus exam',\n",
       " 'exam clear',\n",
       " 'clear speech',\n",
       " 'speech nazi',\n",
       " 'nazi test',\n",
       " 'test memorization',\n",
       " 'memorization class',\n",
       " 'class took',\n",
       " 'took favor',\n",
       " 'favor certain',\n",
       " 'certain student',\n",
       " 'student bell',\n",
       " 'bell everytime',\n",
       " 'everytime struggle',\n",
       " 'struggle little',\n",
       " 'little speech',\n",
       " 'speech ring',\n",
       " 'ring bell',\n",
       " 'bell throw',\n",
       " 'throw nice',\n",
       " 'nice lady',\n",
       " 'lady mellow',\n",
       " 'mellow understanding',\n",
       " 'understanding interested',\n",
       " 'interested writing',\n",
       " 'writing talk',\n",
       " 'talk talk',\n",
       " 'talk textbook',\n",
       " 'textbook needed',\n",
       " 'needed class',\n",
       " 'class but',\n",
       " 'but idea',\n",
       " 'idea talking',\n",
       " 'talking not',\n",
       " 'not reference',\n",
       " 'reference book',\n",
       " 'book oh',\n",
       " 'oh yeah',\n",
       " 'yeah not',\n",
       " 'not book',\n",
       " 'book office',\n",
       " 'office prepare',\n",
       " 'prepare half',\n",
       " 'half hour',\n",
       " 'hour quick',\n",
       " 'quick question',\n",
       " 'question not',\n",
       " 'not stop',\n",
       " 'stop talking',\n",
       " 'talking not',\n",
       " 'not understand',\n",
       " 'understand class',\n",
       " 'class work',\n",
       " 'work best',\n",
       " 'best taechers',\n",
       " 'taechers prepares',\n",
       " 'prepares lecture',\n",
       " 'lecture know',\n",
       " 'know topic',\n",
       " 'topic help',\n",
       " 'help but',\n",
       " 'but beware',\n",
       " 'beware test',\n",
       " 'test hard',\n",
       " 'hard lecture',\n",
       " 'lecture simple',\n",
       " 'simple clear',\n",
       " 'clear provide',\n",
       " 'provide plenty',\n",
       " 'plenty example',\n",
       " 'example typical',\n",
       " 'typical test',\n",
       " 'test question',\n",
       " 'question damn',\n",
       " 'damn shame',\n",
       " 'shame s',\n",
       " 's not',\n",
       " 'not utsa',\n",
       " 'utsa blame',\n",
       " 'blame idiocracy',\n",
       " 'idiocracy took',\n",
       " 'took cepahe',\n",
       " 'cepahe smart',\n",
       " 'smart conscienscious',\n",
       " 'conscienscious engaging',\n",
       " 'engaging not',\n",
       " 'not suffer',\n",
       " 'suffer fool',\n",
       " 'fool gladly',\n",
       " 'gladly downfall',\n",
       " 'downfall social',\n",
       " 'social science',\n",
       " 'science traditional',\n",
       " 'traditional teaching',\n",
       " 'teaching not',\n",
       " 'not use',\n",
       " 'use modern',\n",
       " 'modern way',\n",
       " 'way presenting',\n",
       " 'presenting topic',\n",
       " 'topic basically',\n",
       " 'basically class',\n",
       " 'class time',\n",
       " 'time speaks',\n",
       " 'speaks entire',\n",
       " 'entire time',\n",
       " 'time taking',\n",
       " 'taking exam',\n",
       " 'exam withdrew',\n",
       " 'withdrew method',\n",
       " 'method understanding',\n",
       " 'understanding isnt',\n",
       " 'isnt strongly',\n",
       " 'strongly dont',\n",
       " 'dont recommend',\n",
       " 'recommend professor',\n",
       " 'professor favorite',\n",
       " 'favorite unfair',\n",
       " 'unfair work',\n",
       " 'work hard',\n",
       " 'hard class',\n",
       " 'class grade',\n",
       " 'grade unfairly',\n",
       " 'unfairly inconsistently',\n",
       " 'inconsistently reviewed',\n",
       " 'reviewed work',\n",
       " 'work prof',\n",
       " 'prof definitely',\n",
       " 'definitely class',\n",
       " 'class but',\n",
       " 'but gave',\n",
       " 'gave c',\n",
       " 'c ignores',\n",
       " 'ignores time',\n",
       " 'time try',\n",
       " 'try ask',\n",
       " 'ask question',\n",
       " 'question lecture',\n",
       " 'lecture disorganized',\n",
       " 'disorganized ve',\n",
       " 've never',\n",
       " 'never taken',\n",
       " 'taken spanish',\n",
       " 'spanish class',\n",
       " 'class petty',\n",
       " 'petty hard',\n",
       " 'hard dr',\n",
       " 'dr ramil',\n",
       " 'ramil sweet',\n",
       " 'sweet caring',\n",
       " 'caring life',\n",
       " 'life helpful',\n",
       " 'helpful professor',\n",
       " 'professor lab',\n",
       " 'lab choice',\n",
       " 'choice not',\n",
       " 'not fully',\n",
       " 'fully understand',\n",
       " 'understand material',\n",
       " 'material choose',\n",
       " 'choose spanish',\n",
       " 'spanish class',\n",
       " 'class best',\n",
       " 'best bet',\n",
       " 'bet not',\n",
       " 'not regret',\n",
       " 'regret taking',\n",
       " 'taking class',\n",
       " 'class man',\n",
       " 'man awesome',\n",
       " 'awesome prof',\n",
       " 'prof got',\n",
       " 'got c',\n",
       " 'c helpful',\n",
       " 'helpful situation',\n",
       " 'situation overcome',\n",
       " 'overcome rough',\n",
       " 'rough semester',\n",
       " 'semester knowledge',\n",
       " 'knowledge worst',\n",
       " 'worst teacher',\n",
       " 'teacher delta',\n",
       " 'delta idea',\n",
       " 'idea teaching',\n",
       " 'teaching not',\n",
       " 'not nice',\n",
       " 'nice easygoing',\n",
       " 'easygoing prof',\n",
       " 'prof easy',\n",
       " 'easy come',\n",
       " 'come marking',\n",
       " 'marking essay',\n",
       " 'essay worst',\n",
       " 'worst teacher',\n",
       " 'teacher believe',\n",
       " 'believe got',\n",
       " 'got phd',\n",
       " 'phd cracker',\n",
       " 'cracker jack',\n",
       " 'jack box',\n",
       " 'box not',\n",
       " 'not helpful',\n",
       " 'helpful unable',\n",
       " 'unable explain',\n",
       " 'explain concept',\n",
       " 'concept never',\n",
       " 'never treated',\n",
       " 'treated badly',\n",
       " 'badly asking',\n",
       " 'asking question',\n",
       " 'question pointed',\n",
       " 'pointed inconsistency',\n",
       " 'inconsistency syllabus',\n",
       " 'syllabus belittled',\n",
       " 'belittled massive',\n",
       " 'massive amount',\n",
       " 'amount busy',\n",
       " 'busy work',\n",
       " 'work real',\n",
       " 'real concept',\n",
       " 'concept taught',\n",
       " 'taught worst',\n",
       " 'worst example',\n",
       " 'example teacher',\n",
       " 'teacher seen',\n",
       " 'seen hard',\n",
       " 'hard teacher',\n",
       " 'teacher student',\n",
       " 'student took',\n",
       " 'took class',\n",
       " 'class recieved',\n",
       " 'recieved b',\n",
       " 'b entered',\n",
       " 'entered class',\n",
       " 'class thought',\n",
       " 'thought going',\n",
       " 'going hard',\n",
       " 'hard but',\n",
       " 'but wasn',\n",
       " 'wasn t',\n",
       " 't need',\n",
       " 'need bring',\n",
       " 'bring u',\n",
       " 'u r',\n",
       " 'r clicker',\n",
       " 'clicker class',\n",
       " 'class online',\n",
       " 'online home',\n",
       " 'home work',\n",
       " 'work end',\n",
       " 'end help',\n",
       " 'help u',\n",
       " 'u r',\n",
       " 'r grade',\n",
       " 'grade alot',\n",
       " 'alot barely',\n",
       " 'barely passed',\n",
       " 'passed test',\n",
       " 'test average',\n",
       " 'average grade',\n",
       " 'grade c',\n",
       " 'c little',\n",
       " 'little boring',\n",
       " 'boring but',\n",
       " 'but give',\n",
       " 'give huge',\n",
       " 'huge curve',\n",
       " 'curve end',\n",
       " 'end semester',\n",
       " 'semester not',\n",
       " 'not bad',\n",
       " 'bad pepole',\n",
       " 'pepole but',\n",
       " 'but certainly',\n",
       " 'certainly prone',\n",
       " 'prone going',\n",
       " 'going tangent',\n",
       " 'tangent losing',\n",
       " 'losing class',\n",
       " 'class but',\n",
       " 'but sincere',\n",
       " 'sincere love',\n",
       " 'love material',\n",
       " 'material tough',\n",
       " 'tough remaining',\n",
       " 'remaining awake',\n",
       " 'awake hour',\n",
       " 'hour better',\n",
       " 'better course',\n",
       " 'course mr',\n",
       " 'mr gomez',\n",
       " 'gomez act',\n",
       " 'act like',\n",
       " 'like help',\n",
       " 'help class',\n",
       " 'class isn',\n",
       " 'isn t',\n",
       " 't talk',\n",
       " 'talk victimizes',\n",
       " 'victimizes wouldn',\n",
       " 'wouldn t',\n",
       " 't suggest',\n",
       " 'suggest taking',\n",
       " 'taking class',\n",
       " 'class rude',\n",
       " 'rude need',\n",
       " 'need work',\n",
       " 'work interaction',\n",
       " 'interaction student',\n",
       " 'student good',\n",
       " 'good teacher',\n",
       " 'teacher but',\n",
       " 'but strict',\n",
       " 'strict come',\n",
       " 'come grading',\n",
       " 'grading strong',\n",
       " 'strong accent',\n",
       " 'accent hard',\n",
       " 'hard understand',\n",
       " 'understand but',\n",
       " 'but fun',\n",
       " 'fun character',\n",
       " 'character easy',\n",
       " 'easy but',\n",
       " 'but dont',\n",
       " 'dont know',\n",
       " 'know laughing',\n",
       " 'laughing time',\n",
       " 'time joke',\n",
       " 'joke stup',\n",
       " 'stup beane',\n",
       " 'beane tough',\n",
       " 'tough grader',\n",
       " 'grader not',\n",
       " 'not afraid',\n",
       " 'afraid rip',\n",
       " 'rip apart',\n",
       " 'apart paper',\n",
       " 'paper worked',\n",
       " 'worked hard',\n",
       " 'hard but',\n",
       " 'but not',\n",
       " 'not let',\n",
       " 'let harsh',\n",
       " 'harsh exterior',\n",
       " 'exterior reputation',\n",
       " 'reputation way',\n",
       " 'way taking',\n",
       " 'taking class',\n",
       " 'class extremely',\n",
       " 'extremely helpful',\n",
       " 'helpful speaks',\n",
       " 'speaks french',\n",
       " 'french beautifully',\n",
       " 'beautifully not',\n",
       " 'not easy',\n",
       " 'easy but',\n",
       " 'but guarantee',\n",
       " 'guarantee learn',\n",
       " 'learn class',\n",
       " 'class good',\n",
       " 'good teacher',\n",
       " 'teacher not',\n",
       " 'not b',\n",
       " 'b emery',\n",
       " 'emery helpful',\n",
       " 'helpful clear',\n",
       " 'clear servsafe',\n",
       " 'servsafe hard',\n",
       " 'hard but',\n",
       " 'but glad',\n",
       " 'glad certificate',\n",
       " 'certificate cooked',\n",
       " 'cooked good',\n",
       " 'good meal',\n",
       " 'meal beware',\n",
       " 'beware class',\n",
       " 'class chem',\n",
       " 'chem instead',\n",
       " 'instead test',\n",
       " 'test chem',\n",
       " 'chem directly',\n",
       " 'directly chem',\n",
       " 'chem work',\n",
       " 'work not',\n",
       " 'not need',\n",
       " 'need asperity',\n",
       " 'asperity classroom',\n",
       " 'classroom class',\n",
       " 'class based',\n",
       " 'based note',\n",
       " 'note give',\n",
       " 'give class',\n",
       " 'class dont',\n",
       " 'dont need',\n",
       " 'need textbook',\n",
       " 'textbook u',\n",
       " 'u like',\n",
       " 'like read',\n",
       " 'read test',\n",
       " 'test multiple',\n",
       " 'multiple choice',\n",
       " 'choice pretty',\n",
       " 'pretty easy',\n",
       " 'easy u',\n",
       " 'u little',\n",
       " 'little studying',\n",
       " 'studying pretty',\n",
       " 'pretty mean',\n",
       " 'mean threatens',\n",
       " 'threatens drop',\n",
       " 'drop student',\n",
       " 'student but',\n",
       " 'but doesnt',\n",
       " 'doesnt class',\n",
       " 'class good',\n",
       " 'good overall',\n",
       " 'overall u',\n",
       " 'u dont',\n",
       " 'dont kno',\n",
       " 'kno effort',\n",
       " 'effort talk',\n",
       " 'talk great',\n",
       " 'great guy',\n",
       " 'guy love',\n",
       " 'love talking',\n",
       " 'talking golf',\n",
       " 'golf make',\n",
       " 'make effort',\n",
       " 'effort ask',\n",
       " 'ask wish',\n",
       " 'wish good',\n",
       " 'good weekend',\n",
       " 'weekend class',\n",
       " 'class boring',\n",
       " 'boring but',\n",
       " 'but accounting',\n",
       " 'accounting explains',\n",
       " 'explains material',\n",
       " 'material not',\n",
       " 'not teach',\n",
       " 'teach amazing',\n",
       " 'amazing mind',\n",
       " 'mind know',\n",
       " 'know stuff',\n",
       " 'stuff traveled',\n",
       " 'traveled fantastic',\n",
       " 'fantastic role',\n",
       " 'role model',\n",
       " 'model beautiful',\n",
       " 'beautiful woman',\n",
       " 'woman young',\n",
       " 'young like',\n",
       " 'like said',\n",
       " 'said throw',\n",
       " 'throw question',\n",
       " 'question wouldn',\n",
       " 'wouldn t',\n",
       " 't normally',\n",
       " 'normally catch',\n",
       " 'catch read',\n",
       " 'read book',\n",
       " 'book read',\n",
       " 'read time',\n",
       " 'time time',\n",
       " 'time ask',\n",
       " 'ask question',\n",
       " 'question briefly',\n",
       " 'briefly mentioned',\n",
       " 'mentioned class',\n",
       " 'class never',\n",
       " 'never review',\n",
       " 'review till',\n",
       " 'till pop',\n",
       " 'pop test',\n",
       " 'test stuff',\n",
       " 'stuff went',\n",
       " 'went time',\n",
       " 'time not',\n",
       " 'not great',\n",
       " 'great guy',\n",
       " 'guy class',\n",
       " 'class hour',\n",
       " 'hour long',\n",
       " 'long but',\n",
       " 'but let',\n",
       " 'let early',\n",
       " 'early quiz',\n",
       " 'quiz test',\n",
       " 'test question',\n",
       " 'question usually',\n",
       " 'usually c',\n",
       " 'c etc',\n",
       " 'etc but',\n",
       " 'but didnt',\n",
       " 'didnt work',\n",
       " 'work overtly',\n",
       " 'overtly hard',\n",
       " 'hard got',\n",
       " 'got b',\n",
       " 'b class',\n",
       " 'class quiz',\n",
       " 'quiz class',\n",
       " 'class n',\n",
       " 'n help',\n",
       " 'help final',\n",
       " 'final grade',\n",
       " 'grade loved',\n",
       " 'loved professor',\n",
       " 'professor class',\n",
       " 'class discussion',\n",
       " 'discussion enthusiasm',\n",
       " 'enthusiasm getting',\n",
       " 'getting student',\n",
       " 'student writing',\n",
       " 'writing mood',\n",
       " 'mood got',\n",
       " 'got exited',\n",
       " 'exited professor',\n",
       " 'professor donovan',\n",
       " 'donovan polite',\n",
       " 'polite intelligent',\n",
       " 'intelligent woman',\n",
       " 'woman not',\n",
       " 'not english',\n",
       " 'english but',\n",
       " 'but general',\n",
       " 'general student',\n",
       " 'student not',\n",
       " 'not asked',\n",
       " 'asked good',\n",
       " 'good luck',\n",
       " 'luck excellent',\n",
       " 'excellent teacher',\n",
       " 'teacher never',\n",
       " 'never enjoyed',\n",
       " 'enjoyed history',\n",
       " 'history took',\n",
       " 'took class',\n",
       " 'class harsh',\n",
       " 'harsh grader',\n",
       " 'grader graded',\n",
       " 'graded essay',\n",
       " 'essay but',\n",
       " 'but offer',\n",
       " 'offer let',\n",
       " 'let rewrite',\n",
       " 'rewrite better',\n",
       " 'better grade',\n",
       " 'grade entertaining',\n",
       " 'entertaining lecture',\n",
       " 'lecture watch',\n",
       " 'watch movie',\n",
       " 'movie time',\n",
       " 'time avoid',\n",
       " 'avoid like',\n",
       " 'like viral',\n",
       " 'viral infection',\n",
       " 'infection unclear',\n",
       " 'unclear lecture',\n",
       " 'lecture lab',\n",
       " 'lab grade',\n",
       " 'grade tough',\n",
       " 'tough not',\n",
       " 'not explain',\n",
       " 'explain want',\n",
       " 'want answer',\n",
       " 'answer rude',\n",
       " 'rude demeaning',\n",
       " 'demeaning student',\n",
       " 'student thankfully',\n",
       " 'thankfully retiring',\n",
       " 'retiring worst',\n",
       " 'worst class',\n",
       " 'class far',\n",
       " 'far ucf',\n",
       " 'ucf retake',\n",
       " 'retake organic',\n",
       " 'organic smart',\n",
       " 'smart but',\n",
       " 'but contradicts',\n",
       " 'contradicts say',\n",
       " 'say lecture',\n",
       " 'lecture lab',\n",
       " 'lab great',\n",
       " 'great teacher',\n",
       " 'teacher get',\n",
       " 'get student',\n",
       " 'student great',\n",
       " 'great professor',\n",
       " 'professor class',\n",
       " 'class interesting',\n",
       " 'interesting fair',\n",
       " 'fair grading',\n",
       " 'grading ll',\n",
       " 'll learn',\n",
       " 'learn lot',\n",
       " 'lot class',\n",
       " 'class excellent',\n",
       " 'excellent lecturer',\n",
       " 'lecturer clear',\n",
       " 'clear funny',\n",
       " 'funny great',\n",
       " 'great demo',\n",
       " 'demo extremely',\n",
       " 'extremely hard',\n",
       " 'hard exam',\n",
       " 'exam but',\n",
       " 'but s',\n",
       " 's curve',\n",
       " 'curve shouldn',\n",
       " 'shouldn t',\n",
       " 't affect',\n",
       " 'affect grade',\n",
       " 'grade practice',\n",
       " 'practice lot',\n",
       " 'lot took',\n",
       " 'took class',\n",
       " 'class online',\n",
       " 'online easy',\n",
       " 'easy interesting',\n",
       " 'interesting read',\n",
       " 'read couple',\n",
       " 'couple chapter',\n",
       " 'chapter watch',\n",
       " 'watch video',\n",
       " 'video couple',\n",
       " 'couple pretty',\n",
       " 'pretty long',\n",
       " 'long easy',\n",
       " 'easy quiz',\n",
       " 'quiz week',\n",
       " 'week clear',\n",
       " 'clear syllabus',\n",
       " 'syllabus quick',\n",
       " 'quick response',\n",
       " 'response email',\n",
       " 'email definitely',\n",
       " 'definitely recommend',\n",
       " 'recommend interested',\n",
       " 'interested subject',\n",
       " 'subject need',\n",
       " 'need easy',\n",
       " 'easy credit',\n",
       " 'credit taking',\n",
       " 'taking pop',\n",
       " 'pop jazz',\n",
       " 'jazz theory',\n",
       " 'theory dr',\n",
       " 'dr kearney',\n",
       " 'kearney decided',\n",
       " 'decided wanted',\n",
       " 'wanted major',\n",
       " 'major music',\n",
       " 'music good',\n",
       " 'good man',\n",
       " 'man know',\n",
       " 'know want',\n",
       " 'want know',\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "all_words = \" \".join(comments_proper)\n",
    "all_words = all_words.split()\n",
    "bgs = nltk.bigrams(all_words)\n",
    "bigram_feature_vector = []\n",
    "for item in nltk.bigrams(all_words):\n",
    "    bigram_feature_vector.append(\" \".join(item))\n",
    "bigram_feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Precision and Recall of Model\n",
    "\n",
    "See https://en.m.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.7217138103161398; Recall=0.7411362665527552\n"
     ]
    }
   ],
   "source": [
    "# Precision wrt 0\n",
    "prec_0 = conf_m[0][0] / float(conf_m[1][0] + conf_m[0][0])\n",
    "\n",
    "# Recall wrt 0\n",
    "rec_0 = conf_m[0][0] / float(conf_m[0][1] + conf_m[0][0])\n",
    "\n",
    "print(\"Precision={0}; Recall={1}\".format(prec_0,rec_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.9085144927536232; Recall=0.8999551368326604\n"
     ]
    }
   ],
   "source": [
    "# Precision wrt 1\n",
    "prec_1 = conf_m[1][1] / float(conf_m[0][1] + conf_m[1][1])\n",
    "\n",
    "# Recall wrt 1\n",
    "rec_1 = conf_m[1][1] / float(conf_m[1][0] + conf_m[1][1])\n",
    "\n",
    "print(\"Precision={0}; Recall={1}\".format(prec_1,rec_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.8600762564237441; Recall=0.8587727071333628\n"
     ]
    }
   ],
   "source": [
    "# More refined way to calculate precision and recall, should've done my research first lol\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"Precision={0}; Recall={1}\".format(precision, recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed8ce2715666cca47edfe3dc40f16f58fc193b5a7b06958e2ae06c97afdf9990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
