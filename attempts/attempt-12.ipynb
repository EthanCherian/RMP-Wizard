{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use negation tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_selection import chi2, SelectPercentile\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"../Data/scraped_comments_with_professor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.drop_duplicates(subset=\"comment_id\", keep=\"first\", inplace=True)\n",
    "\n",
    "reviews.dropna(subset=[\"comment\"], inplace=True)\n",
    "reviews = reviews[reviews[\"comment\"] != \"No Comments\"]\n",
    "\n",
    "reviews['firstName'].fillna('', inplace=True)\n",
    "reviews['lastName'].fillna('', inplace=True)\n",
    "\n",
    "reviews[\"comment\"] = reviews[\"comment\"].apply(lambda x: x if len(x.split()) > 5 else None)\n",
    "reviews.dropna(subset=[\"comment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 5.0    176812\n",
       " 4.5     58705\n",
       " 4.0     52643\n",
       " 1.0     45128\n",
       " 2.0     26945\n",
       " 3.5     22896\n",
       " 1.5     19230\n",
       " 2.5     17510\n",
       "-1.0         1\n",
       "Name: starRating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"starRating\"] = (reviews[\"clarityRating\"] + reviews[\"helpfulRating\"]) / 2\n",
    "reviews = reviews[reviews[\"starRating\"] != 3.0]         # drop 3 star reviews\n",
    "reviews.reset_index(drop=True, inplace=True)\n",
    "\n",
    "reviews[\"starRating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
    "\n",
    "def remove_phones(text):\n",
    "    return re.sub(r'\\d{3}-\\d{3}-\\d{4}', ' ', text)\n",
    "\n",
    "def remove_emails(text):\n",
    "    return re.sub(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', ' ', text)\n",
    "\n",
    "def remove_html_entities(text):\n",
    "  text = re.sub('&[0-9a-zA-Z#]+;', ' ', text)\n",
    "  return re.sub('&#63;?', '', text)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "  return re.sub('<.{1,6}?>', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = [\"not\", \"no\", \"nor\", \"neither\"]\n",
    "puncts = [\".\", \",\", \"!\", \"?\"]\n",
    "\n",
    "def negationTag(comment):\n",
    "    new_comment = []\n",
    "    negation_flag = False\n",
    "    for token in nltk.word_tokenize(comment):\n",
    "        if token in negative_words:\n",
    "            negation_flag = True\n",
    "            continue\n",
    "        if negation_flag == True:\n",
    "            if token in puncts:\n",
    "                negation_flag = False\n",
    "            else:\n",
    "                token = \"neg_\" + token\n",
    "        \n",
    "        new_comment.append(token)\n",
    "    \n",
    "    return \" \".join(new_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This class is neg_great . neg_was neg_it neg_informational .'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negationTag(\"This class is not very hard. According to a friend, neither are our other classes.\")\n",
    "negationTag(\"This class is not great. nor was it informational.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTICONS = {\n",
    "    u\":‑)\":\"emopos\",\n",
    "    u\":-))\":\"emopos\",\n",
    "    u\":-)))\":\"emopos\",\n",
    "    u\":)\":\"emopos\",\n",
    "    u\":))\":\"emopos\",\n",
    "    u\":)))\":\"emopos\",\n",
    "    u\":-]\":\"emopos\",\n",
    "    u\":]\":\"emopos\",\n",
    "    u\":-3\":\"emopos\",\n",
    "    u\":3\":\"emopos\",\n",
    "    u\":->\":\"emopos\",\n",
    "    u\":>\":\"emopos\",\n",
    "    u\"8-)\":\"emopos\",\n",
    "    u\":-}\":\"emopos\",\n",
    "    u\":}\":\"emopos\",\n",
    "    u\":-)\":\"emopos\",\n",
    "    u\":c)\":\"emopos\",\n",
    "    u\":^)\":\"emopos\",\n",
    "    u\"=]\":\"emopos\",\n",
    "    u\"=)\":\"emopos\",\n",
    "    u\":‑D\":\"emopos\",\n",
    "    u\":D\":\"emopos\",\n",
    "    u\"8‑D\":\"emopos\",\n",
    "    u\"8D\":\"emopos\",\n",
    "    u\"X‑D\":\"emopos\",\n",
    "    u\"XD\":\"emopos\",\n",
    "    u\"=D\":\"emopos\",\n",
    "    u\"=3\":\"emopos\",\n",
    "    u\"B^D\":\"emopos\",\n",
    "    u\":-))\":\"emopos\",\n",
    "    u\":-(\":\"emoneg\",\n",
    "    u\":‑(\":\"emoneg\",\n",
    "    u\":(\":\"emoneg\",\n",
    "    u\":‑c\":\"emoneg\",\n",
    "    u\":c\":\"emoneg\",\n",
    "    u\":‑<\":\"emoneg\",\n",
    "    u\":<\":\"emoneg\",\n",
    "    u\":‑[\":\"emoneg\",\n",
    "    u\":[\":\"emoneg\",\n",
    "    u\":-||\":\"emoneg\",\n",
    "    u\">:[\":\"emoneg\",\n",
    "    u\":{\":\"emoneg\",\n",
    "    u\">:(\":\"emoneg\",\n",
    "    u\":'‑(\":\"emoneg\",\n",
    "    u\":'(\":\"emoneg\",\n",
    "    u\":'‑)\":\"emopos\",\n",
    "    u\":')\":\"emopos\",\n",
    "    u\"D‑':\":\"emoneg\",\n",
    "    u\"D:<\":\"emoneg\",\n",
    "    u\"D:\":\"emoneg\",\n",
    "    u\"D8\":\"emoneg\",\n",
    "    u\"D;\":\"emoneg\",\n",
    "    u\"D=\":\"emoneg\",\n",
    "    u\"DX\":\"emoneg\",\n",
    "    u\";‑)\":\"emopos\",\n",
    "    u\";)\":\"emopos\",\n",
    "    u\"*-)\":\"emopos\",\n",
    "    u\"*)\":\"emopos\",\n",
    "    u\";‑]\":\"emopos\",\n",
    "    u\";]\":\"emopos\",\n",
    "    u\";^)\":\"emopos\",\n",
    "    u\":‑,\":\"emopos\",\n",
    "    u\";D\":\"emopos\",\n",
    "    u\":‑P\":\"emopos\",\n",
    "    u\":P\":\"emopos\",\n",
    "    u\"X‑P\":\"emopos\",\n",
    "    u\"XP\":\"emopos\",\n",
    "    u\":‑Þ\":\"emopos\",\n",
    "    u\":Þ\":\"emopos\",\n",
    "    u\"=p\":\"emopos\",\n",
    "    u\":‑/\":\"emoneg\",\n",
    "    u\":/\":\"emoneg\",\n",
    "    u\":-[.]\":\"emoneg\",\n",
    "    u\">:[(\\)]\":\"emoneg\",\n",
    "    u\">:/\":\"emoneg\",\n",
    "    u\":[(\\)]\":\"emoneg\",\n",
    "    u\"=/\":\"emoneg\",\n",
    "    u\"=[(\\)]\":\"emoneg\",\n",
    "    u\":L\":\"emoneg\",\n",
    "    u\"=L\":\"emoneg\",\n",
    "    u\":‑|\":\"emoneg\",\n",
    "    u\":|\":\"emoneg\",\n",
    "    u\"O:‑)\":\"emopos\",\n",
    "    u\"O:)\":\"emopos\",\n",
    "    u\"0:‑3\":\"emopos\",\n",
    "    u\"0:3\":\"emopos\",\n",
    "    u\"0:‑)\":\"emopos\",\n",
    "    u\"0:)\":\"emopos\",\n",
    "    u\":‑b\":\"emopos\",\n",
    "    u\"(>_<)\":\"emoneg\",\n",
    "    u\"(>_<)>\":\"emoneg\",\n",
    "    u\"^_^\":\"emopos\",\n",
    "    u\"(^_^)/\":\"emopos\",\n",
    "    u\"(^O^)／\":\"emopos\",\n",
    "    u\"(^o^)／\":\"emopos\",\n",
    "    u\"('_')\":\"emoneg\",\n",
    "    u\"(/_;)\":\"emoneg\",\n",
    "    u\"(T_T) (;_;)\":\"emoneg\",\n",
    "    u\"(;_;\":\"emoneg\",\n",
    "    u\"(;_:)\":\"emoneg\",\n",
    "    u\"(;O;)\":\"emoneg\",\n",
    "    u\"(:_;)\":\"emoneg\",\n",
    "    u\"(ToT)\":\"emoneg\",\n",
    "    u\";_;\":\"emoneg\",\n",
    "    u\";-;\":\"emoneg\",\n",
    "    u\";n;\":\"emoneg\",\n",
    "    u\";n;\":\"emoneg\",\n",
    "    u\"Q.Q\":\"emoneg\",\n",
    "    u\"T.T\":\"emoneg\",\n",
    "    u\"Q_Q\":\"emoneg\",\n",
    "    u\"(-.-)\":\"emopos\",\n",
    "    u\"(-_-)\":\"emopos\",\n",
    "    u\"(；一_一)\":\"emopos\",\n",
    "    u\"(=_=)\":\"emoneg\",\n",
    "    u\"^m^\":\"emopos\",\n",
    "    u\">^_^<\":\"emopos\",\n",
    "    u\"<^!^>\":\"emopos\",\n",
    "    u\"^/^\":\"emopos\",\n",
    "    u\"（*^_^*）\" :\"emopos\",\n",
    "    u\"(^<^) (^.^)\":\"emopos\",\n",
    "    u\"(^^)\":\"emopos\",\n",
    "    u\"(^.^)\":\"emopos\",\n",
    "    u\"(^_^.)\":\"emopos\",\n",
    "    u\"(^_^)\":\"emopos\",\n",
    "    u\"(^^)\":\"emopos\",\n",
    "    u\"(^J^)\":\"emopos\",\n",
    "    u\"(*^.^*)\":\"emopos\",\n",
    "    u\"(^—^）\":\"emopos\",\n",
    "    u\"(#^.^#)\":\"emopos\",\n",
    "    u\"(*^0^*)\":\"emopos\",\n",
    "    u\"(*^^)v\":\"emopos\",\n",
    "    u\"(^_^)v\":\"emopos\",\n",
    "    u'(-\"-)':\"emoneg\",\n",
    "    u\"(ーー;)\":\"emoneg\",\n",
    "    u\"(＾ｖ＾)\":\"emopos\",\n",
    "    u\"(＾ｕ＾)\":\"emopos\",\n",
    "    u\"(^)o(^)\":\"emopos\",\n",
    "    u\"(^O^)\":\"emopos\",\n",
    "    u\"(^o^)\":\"emopos\",\n",
    "    u\")^o^(\":\"emopos\",\n",
    "    u\":O o_O\":\"emoneg\",\n",
    "    u\"o_0\":\"emoneg\",\n",
    "    u\"o.O\":\"emoneg\",\n",
    "    u\"(o.o)\":\"emoneg\",\n",
    "    u\"(*￣m￣)\": \"emoneg\",\n",
    "}\n",
    "\n",
    "for emote, val in EMOTICONS.items():\n",
    "    EMOTICONS[emote] = val.lower().replace(',', ' ').replace(' ', '_')\n",
    "\n",
    "def convert_emoticons(text):\n",
    "  return EMOTICONS.get(text, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTIONS = {\n",
    "    \"won't\": \"will not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"isn't\": \"is not\"\n",
    "}\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return CONTRACTIONS.get(text, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"he\", \"her\", \"she\", \"him\", \"guy\", \"we\", \"professor\", \"professors\", \"prof\", \"profs\", \"teacher\", \"teachers\", \"mr\", \"ms\", \"mrs\",\n",
    "\"dr\", \"doctor\", \"class\", \"classes\", \"course\", \"courses\", \"college\", \"colleges\", \"university\", \"universities\", \"lecture\", \"lectures\", \"lab\", \"labs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(reviews: pd.DataFrame):\n",
    "    comments_proper = []\n",
    "    unseen = Counter()\n",
    "\n",
    "    for index, review in reviews.iterrows():\n",
    "        comment = review['comment']\n",
    "        fname = review['firstName'].lower().split(' ')\n",
    "        lname = review['lastName'].lower().split(' ')\n",
    "        names = set(fname + lname)\n",
    "\n",
    "        comment = remove_urls(comment)\n",
    "        comment = remove_phones(comment)\n",
    "        comment = remove_emails(comment)\n",
    "        comment = remove_html_entities(comment)\n",
    "        comment = remove_html_tags(comment)\n",
    "\n",
    "        comment_split = comment.split(' ')\n",
    "        new_comment_split = []\n",
    "        for i, word in enumerate(comment_split):\n",
    "            word = convert_emoticons(word)\n",
    "            word = word.lower()\n",
    "            word = expand_contractions(word)\n",
    "            word = re.sub(\"[^a-zA-Z\\s]+\", ' ', word)   # replace characters that are not alphabetic, space, or underscore\n",
    "            word = re.sub(r'(.)\\1\\1+', '\\g<1>', word)  # replace any three character+ sequence with one\n",
    "            word = re.sub('\\s+', ' ', word)\n",
    "            word = word.strip() # trailing whitespace because punctuation replaced by space\n",
    "            new_comment_split.extend(word.split(' '))\n",
    "\n",
    "        # Remove names from the comment\n",
    "        for i, word in enumerate(new_comment_split):\n",
    "            if word in names:\n",
    "                new_comment_split[i] = ''\n",
    "\n",
    "        # putting negation tagging line here improves accuracy *a lot*\n",
    "        # probably bc putting it here essentially leads to negation tagging being ignored lol\n",
    "\n",
    "        comment = ' '.join(new_comment_split)\n",
    "        comment = re.sub('\\s+', ' ', comment)\n",
    "        comment = comment.strip()\n",
    "\n",
    "        comment = negationTag(comment)        # tag words following negation words as negated\n",
    "\n",
    "        comment = ' '.join(word for word in comment.split() if len(word) > 1 and word not in stopwords)\n",
    "\n",
    "        comments_proper.append(comment)\n",
    "\n",
    "    return comments_proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_proper = preproc(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professor_id</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>comment</th>\n",
       "      <th>starRating</th>\n",
       "      <th>cleanedComment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VGVhY2hlci0xMjQzMzQ3</td>\n",
       "      <td>Kurt</td>\n",
       "      <td>Douglass</td>\n",
       "      <td>Good teacher, good lectures. Obviously cares a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good good obviously cares about the subject ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VGVhY2hlci0xMjQzMzQ3</td>\n",
       "      <td>Kurt</td>\n",
       "      <td>Douglass</td>\n",
       "      <td>Good teacher, very lenient with grading and at...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good very lenient with grading and attendance ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGVhY2hlci0xMjQzMzQ3</td>\n",
       "      <td>Kurt</td>\n",
       "      <td>Douglass</td>\n",
       "      <td>Very difficult class.  His grading is hard to ...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>very difficult his grading is hard to understa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VGVhY2hlci0xMDExMDU2</td>\n",
       "      <td>Paula</td>\n",
       "      <td>Zobisch</td>\n",
       "      <td>Excellent mentor. Created valuable foundations...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>excellent mentor created valuable foundations ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VGVhY2hlci0xMDExMDU2</td>\n",
       "      <td>Paula</td>\n",
       "      <td>Zobisch</td>\n",
       "      <td>Awesome...Had her for two classes at baker col...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>awesome had for two at baker reccommended</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           professor_id firstName  lastName  \\\n",
       "0  VGVhY2hlci0xMjQzMzQ3      Kurt  Douglass   \n",
       "1  VGVhY2hlci0xMjQzMzQ3      Kurt  Douglass   \n",
       "2  VGVhY2hlci0xMjQzMzQ3      Kurt  Douglass   \n",
       "3  VGVhY2hlci0xMDExMDU2     Paula   Zobisch   \n",
       "4  VGVhY2hlci0xMDExMDU2     Paula   Zobisch   \n",
       "\n",
       "                                             comment  starRating  \\\n",
       "0  Good teacher, good lectures. Obviously cares a...         5.0   \n",
       "1  Good teacher, very lenient with grading and at...         5.0   \n",
       "2  Very difficult class.  His grading is hard to ...         1.5   \n",
       "3  Excellent mentor. Created valuable foundations...         5.0   \n",
       "4  Awesome...Had her for two classes at baker col...         5.0   \n",
       "\n",
       "                                      cleanedComment  sentiment  \n",
       "0  good good obviously cares about the subject ma...          1  \n",
       "1  good very lenient with grading and attendance ...          1  \n",
       "2  very difficult his grading is hard to understa...          0  \n",
       "3  excellent mentor created valuable foundations ...          1  \n",
       "4          awesome had for two at baker reccommended          1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews.loc[:, [\"professor_id\", \"firstName\", \"lastName\", \"comment\", \"starRating\"]]\n",
    "reviews[\"cleanedComment\"] = pd.Series(comments_proper)\n",
    "reviews[\"sentiment\"] = reviews[\"starRating\"].apply(lambda x: 1 if x > 2.5 else 0)\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_counts = reviews[\"professor_id\"].value_counts()\n",
    "prof_train, prof_test, cnt_train, cnt_test = train_test_split(prof_counts.index, prof_counts.values, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_train = reviews[reviews[\"professor_id\"].isin(prof_train)][\"cleanedComment\"]\n",
    "comm_test = reviews[reviews[\"professor_id\"].isin(prof_test)][\"cleanedComment\"]\n",
    "\n",
    "sent_train = reviews[reviews[\"professor_id\"].isin(prof_train)][\"sentiment\"]\n",
    "sent_test = reviews[reviews[\"professor_id\"].isin(prof_test)][\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1,2), max_df=0.5)), \n",
    "    (\"selector\"  , SelectPercentile(score_func=chi2, percentile=50)),\n",
    "    (\"classifer\" , MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evalPerformance(y_pred, y_test, mode=\"weighted\"):\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \" + str(acc_score * 100))\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, average=mode)\n",
    "    print(\"F1 Score: {0}\\n\".format(f1 * 100))\n",
    "\n",
    "    prec = precision_score(y_test, y_pred, average=mode)\n",
    "    print(\"Precision: {0}\".format(prec * 100))\n",
    "    rec = recall_score(y_test, y_pred, average=mode)\n",
    "    print(\"Recall: {0}\\n\".format(rec * 100))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_fit = pipeline.fit(comm_train, sent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pred = sentiment_fit.predict(comm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.7391283852264\n",
      "F1 Score: 83.98545557803826\n",
      "\n",
      "Precision: 84.36174673856573\n",
      "Recall: 83.7391283852264\n",
      "\n",
      "[[16279  5774]\n",
      " [ 8024 54777]]\n"
     ]
    }
   ],
   "source": [
    "evalPerformance(sent_pred, sent_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_reviews = pd.read_csv(\"../Data/scraped_comments.csv\").sample(n=100000, random_state=1)\n",
    "\n",
    "old_reviews.drop_duplicates(subset=\"comment_id\", keep=\"first\", inplace=True)\n",
    "\n",
    "old_reviews.dropna(subset=[\"comment\"], inplace=True)\n",
    "old_reviews = old_reviews[old_reviews[\"comment\"] != \"No Comments\"]\n",
    "old_reviews[\"comment\"] = old_reviews[\"comment\"].apply(lambda x: x if len(x.split()) > 5 else None)\n",
    "old_reviews.dropna(subset=[\"comment\"], inplace=True)\n",
    "\n",
    "old_reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_reviews[\"starRating\"] = (old_reviews[\"clarityRating\"] + old_reviews[\"helpfulRating\"]) / 2\n",
    "old_reviews = old_reviews[old_reviews[\"starRating\"] != 3.0]         # drop 3 star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_reviews = old_reviews[old_reviews[\"clarityRating\"] == old_reviews[\"helpfulRating\"]]\n",
    "old_reviews.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_comments = preproc(old_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = sentiment_fit.predict(preproc_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.26323478387904\n",
      "F1 Score: 85.4010619384567\n",
      "\n",
      "Precision: 85.59684498324553\n",
      "Recall: 85.26323478387904\n",
      "\n",
      "[[11447  3557]\n",
      " [ 4513 35244]]\n"
     ]
    }
   ],
   "source": [
    "real_sentiment = old_reviews[\"starRating\"].apply(lambda x: 1 if x > 2.5 else 0)\n",
    "evalPerformance(preds, real_sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed8ce2715666cca47edfe3dc40f16f58fc193b5a7b06958e2ae06c97afdf9990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
