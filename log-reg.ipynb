{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a logistic regression model for sentiment analysis\n",
    "\n",
    "Borrowed heavily (almost entirely from) https://kavita-ganesan.com/news-classifier-with-logistic-regression-in-python/#.Yui_xXbMKUl\n",
    "\n",
    "Code also on git at https://github.com/kavgan/nlp-in-practice/blob/2d9e23c1d8ab56e9533be188c9ce7a0f6efc11e1/text-classification/notebooks/Text%20Classification%20with%20Logistic%20Regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>comment</th>\n",
       "      <th>clarityRating</th>\n",
       "      <th>cleaned comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marty</td>\n",
       "      <td>Beans</td>\n",
       "      <td>Very nice and understanding. A lot of homework...</td>\n",
       "      <td>4</td>\n",
       "      <td>nice understand lot homework grade problem num...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marty</td>\n",
       "      <td>Beans</td>\n",
       "      <td>She is very helpful. Gives EC if you go to tut...</td>\n",
       "      <td>4</td>\n",
       "      <td>helpful ec tutor poor office hour , willing he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marty</td>\n",
       "      <td>Beans</td>\n",
       "      <td>she was nice. good job her</td>\n",
       "      <td>4</td>\n",
       "      <td>nice good job</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marty</td>\n",
       "      <td>Beans</td>\n",
       "      <td>Professor Beans is one of the best Math teache...</td>\n",
       "      <td>5</td>\n",
       "      <td>professor bean good math teacher come absolute...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marty</td>\n",
       "      <td>Beans</td>\n",
       "      <td>Big smile. Big goals. Nice lady. Bright and ch...</td>\n",
       "      <td>5</td>\n",
       "      <td>big smile big goal nice lady bright cheery swe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  firstName lastName                                            comment  \\\n",
       "0     Marty    Beans  Very nice and understanding. A lot of homework...   \n",
       "1     Marty    Beans  She is very helpful. Gives EC if you go to tut...   \n",
       "2     Marty    Beans                         she was nice. good job her   \n",
       "3     Marty    Beans  Professor Beans is one of the best Math teache...   \n",
       "4     Marty    Beans  Big smile. Big goals. Nice lady. Bright and ch...   \n",
       "\n",
       "   clarityRating                                    cleaned comment  sentiment  \n",
       "0              4  nice understand lot homework grade problem num...          1  \n",
       "1              4  helpful ec tutor poor office hour , willing he...          1  \n",
       "2              4                                      nice good job          1  \n",
       "3              5  professor bean good math teacher come absolute...          1  \n",
       "4              5  big smile big goal nice lady bright cheery swe...          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"comments_preproc.csv\", index_col=0)#.sample(n=50000, random_state=0)\n",
    "reviews.reset_index(drop=True, inplace=True)\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interestingly, some comments are entirely empty after being sampled\n",
    "\n",
    "They must have been entirely consistent of stop words that just got removed lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"sentiment\"] = reviews[\"clarityRating\"].apply(lambda x: 1 if x > 3 else 0 if x == 3 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"cleaned comment\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.dropna(subset=[\"cleaned comment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next few cells are function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using different available methods\n",
    "\n",
    "def extract_features(df, train_data, test_data, type=\"binary\"):\n",
    "    if \"binary\" in type:\n",
    "        # binary feature representation\n",
    "        \n",
    "        cv = CountVectorizer(binary=True, max_df=0.95)\n",
    "        cv.fit_transform(train_data[\"cleaned comment\"].values)\n",
    "\n",
    "        train_features = cv.transform(train_data[\"cleaned comment\"].values)\n",
    "        test_features = cv.transform(test_data[\"cleaned comment\"].values)\n",
    "\n",
    "        return train_features, test_features, cv\n",
    "    \n",
    "    elif \"counts\" in type:\n",
    "        # count-based feature representation\n",
    "\n",
    "        cv = CountVectorizer(binary=False, max_df=0.95)\n",
    "        cv.fit_transform(train_data[\"cleaned comment\"].values)\n",
    "\n",
    "        train_features = cv.transform(train_data[\"cleaned comment\"].values)\n",
    "        test_features = cv.transform(test_data[\"cleaned comment\"].values)\n",
    "\n",
    "        return train_features, test_features, cv\n",
    "    \n",
    "    else:\n",
    "        # TF-IDF based feature representation\n",
    "\n",
    "        tfidf_vec = TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "        tfidf_vec.fit_transform(train_data[\"cleaned comment\"].values)\n",
    "\n",
    "        train_features = tfidf_vec.transform(train_data[\"cleaned comment\"].values)\n",
    "        test_features = tfidf_vec.transform(test_data[\"cleaned comment\"].values)\n",
    "\n",
    "        return train_features, test_features, tfidf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_predictions(model, X_test, k):\n",
    "    probs = model.predict_proba(X_test)         # get probabilities instead of labels\n",
    "    best_n = np.argsort(probs, axis=1)[:,-k:]   # get top k predictions by index (note: just index)\n",
    "\n",
    "    preds = [[model.classes_[predicted_cat] for predicted_cat in prediction] for prediction in best_n]          # get category of predictions\n",
    "    preds = [item[::-1] for item in preds]     # reverse categories, descending order of importance\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_preds(Y_test, Y_preds):\n",
    "    pred_gold_list=[[[Y_test[idx]],pred] for idx,pred in enumerate(Y_preds)]\n",
    "    return pred_gold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(eval_items:list):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for item in eval_items:\n",
    "        true_pred = item[0]\n",
    "        machine_pred = set(item[1])\n",
    "\n",
    "        for cat in true_pred:\n",
    "            if cat in machine_pred:\n",
    "                correct += 1\n",
    "    accuracy = correct/float(len(eval_items))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reciprocal_rank(true_labels:list, machine_preds:list):\n",
    "    tp_pos_list = [(idx + 1) for idx, r in enumerate(machine_preds) if r in true_labels]\n",
    "    \n",
    "    rr = 0\n",
    "    if len(tp_pos_list) > 0:\n",
    "        first_pos_list = tp_pos_list[0]\n",
    "        rr = 1 / float(first_pos_list)\n",
    "    \n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean reciprocal rank, which I understand as follows\n",
    "\"\"\" this is admittedly much more useful when dealing with multiple categories\n",
    "essentially, how many of the relevant categories appear in the top k predicted categories (or something to that effect, as it's typically shown as a percentage)\n",
    "as our data currently has two possible categories, if we let top_k=2, everything comes out to 100% lol, and if top_k=1, accuracy and mrr are the same\n",
    "\"\"\"\n",
    "\n",
    "def compute_mrr_at_k(items:list):\n",
    "    rr_total = 0\n",
    "\n",
    "    for item in items:\n",
    "        rr_at_k = _reciprocal_rank(item[0], item[1])\n",
    "        rr_total += rr_at_k\n",
    "        mrr = rr_total / 1/float(len(items))\n",
    "    \n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, field=\"cleaned comments\", feature_rep=\"binary\", top_k=1):\n",
    "    train_data, test_data = train_test_split(df, random_state=0)            # get train-test split\n",
    "    y_train = train_data[\"sentiment\"].values                                # isolate labels in training and testing data\n",
    "    y_test = test_data[\"sentiment\"].values\n",
    "\n",
    "    X_train, X_test, feature_transformer = extract_features(reviews, train_data, test_data, type=feature_rep)           # get features\n",
    "\n",
    "    log_reg = LogisticRegression(verbose=1, solver=\"liblinear\", random_state=0, C=5, penalty=\"l2\", max_iter=1000)       # create model and fit to training data\n",
    "    model = log_reg.fit(X_train, y_train)\n",
    "\n",
    "    preds = get_top_k_predictions(model, X_test, top_k)                 # get k most relevant predictions\n",
    "\n",
    "    eval_items = collect_preds(y_test, preds)                           # get predicted values and ground into list of lists (for ease of evaluation)\n",
    "\n",
    "    accuracy = compute_accuracy(eval_items)                             # get final stats on success rate of model\n",
    "    mrr_at_k = compute_mrr_at_k(eval_items)\n",
    "\n",
    "    return model, feature_transformer, accuracy, mrr_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finally ready to start actually using the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING BINARY FEATURE REPRESENTATION ***\n",
      "Accuracy=0.7714593695854202; MRR=0.7714593695854202\n"
     ]
    }
   ],
   "source": [
    "feature = \"binary\"\n",
    "top_k = 1\n",
    "\n",
    "model, transformer, accuracy, mrr = train_model(reviews, \"cleaned comments\", feature_rep=feature, top_k=top_k)\n",
    "print(\"\\n*** USING BINARY FEATURE REPRESENTATION ***\")\n",
    "print(\"Accuracy={0}; MRR={1}\".format(accuracy,mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "feature = \"count\"\n",
    "top_k = 1\n",
    "\n",
    "model, transformer, accuracy, mrr = train_model(reviews, \"cleaned comments\", feature_rep=feature, top_k=top_k)\n",
    "print(\"\\n*** USING COUNT-BASED FEATURE REPRESENTATION ***\")\n",
    "print(\"Accuracy={0}; MRR={1}\".format(accuracy,mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"tfidf\"\n",
    "top_k = 1\n",
    "\n",
    "model, transformer, accuracy, mrr = train_model(reviews, \"cleaned comments\", feature_rep=feature, top_k=top_k)\n",
    "print(\"\\n*** USING TF-IDF FEATURE REPRESENTATION ***\")\n",
    "print(\"Accuracy={0}; MRR={1}\".format(accuracy,mrr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed8ce2715666cca47edfe3dc40f16f58fc193b5a7b06958e2ae06c97afdf9990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
