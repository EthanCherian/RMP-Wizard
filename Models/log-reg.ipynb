{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a logistic regression model for sentiment analysis\n",
    "\n",
    "Borrowed heavily (almost entirely from) https://kavita-ganesan.com/news-classifier-with-logistic-regression-in-python/#.Yui_xXbMKUl\n",
    "\n",
    "Code also on git at https://github.com/kavgan/nlp-in-practice/blob/2d9e23c1d8ab56e9533be188c9ce7a0f6efc11e1/text-classification/notebooks/Text%20Classification%20with%20Logistic%20Regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastName</th>\n",
       "      <th>comment</th>\n",
       "      <th>clarityRating</th>\n",
       "      <th>cleanedComment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Williams</td>\n",
       "      <td>A great professor who really cares about his s...</td>\n",
       "      <td>5</td>\n",
       "      <td>great professor care student</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lehman</td>\n",
       "      <td>I don't know why people would say he does not ...</td>\n",
       "      <td>5</td>\n",
       "      <td>not know people not care class not accept b gi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Glade</td>\n",
       "      <td>Even though the book you have to read is prett...</td>\n",
       "      <td>4</td>\n",
       "      <td>book read pretty difficult test easy answer di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heckelman</td>\n",
       "      <td>Good teacher, although his lectures are very s...</td>\n",
       "      <td>4</td>\n",
       "      <td>good teacher lecture stale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lipset</td>\n",
       "      <td>Rude to students with questions, dry speech, r...</td>\n",
       "      <td>3</td>\n",
       "      <td>rude student question dry speech ramble easy c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lastName                                            comment  \\\n",
       "0   Williams  A great professor who really cares about his s...   \n",
       "1     Lehman  I don't know why people would say he does not ...   \n",
       "2      Glade  Even though the book you have to read is prett...   \n",
       "3  Heckelman  Good teacher, although his lectures are very s...   \n",
       "4     Lipset  Rude to students with questions, dry speech, r...   \n",
       "\n",
       "   clarityRating                                     cleanedComment  sentiment  \n",
       "0              5                       great professor care student          1  \n",
       "1              5  not know people not care class not accept b gi...          1  \n",
       "2              4  book read pretty difficult test easy answer di...          1  \n",
       "3              4                         good teacher lecture stale          1  \n",
       "4              3  rude student question dry speech ramble easy c...          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"comments_preproc.csv\", index_col=0).sample(n=200000, random_state=0)\n",
    "reviews.reset_index(drop=True, inplace=True)\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interestingly, some comments are entirely empty after being sampled\n",
    "\n",
    "They must have been entirely consistent of stop words that just got removed lmao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews[\"sentiment\"] = reviews[\"clarityRating\"].apply(lambda x: 1 if x > 3 else 0 if x == 3 else -1)\n",
    "reviews[\"sentiment\"] = reviews[\"clarityRating\"].apply(lambda x: 1 if x > 2.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"cleanedComment\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.dropna(subset=[\"cleanedComment\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next few cells are function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using different available methods\n",
    "\n",
    "def extract_features(df, train_data, test_data, type=\"binary\", ngr=(1,1)):\n",
    "    if \"binary\" in type:\n",
    "        # binary feature representation\n",
    "        \n",
    "        cv = CountVectorizer(binary=True, max_df=0.95, ngram_range=ngr)\n",
    "        cv.fit_transform(train_data[\"cleanedComment\"].values)\n",
    "\n",
    "        train_features = cv.transform(train_data[\"cleanedComment\"].values)\n",
    "        test_features = cv.transform(test_data[\"cleanedComment\"].values)\n",
    "\n",
    "        return train_features, test_features, cv\n",
    "    \n",
    "    elif \"counts\" in type:\n",
    "        # count-based feature representation\n",
    "\n",
    "        cv = CountVectorizer(binary=False, max_df=0.95, ngram_range=ngr)\n",
    "        cv.fit_transform(train_data[\"cleanedComment\"].values)\n",
    "\n",
    "        train_features = cv.transform(train_data[\"cleanedComment\"].values)\n",
    "        test_features = cv.transform(test_data[\"cleanedComment\"].values)\n",
    "\n",
    "        return train_features, test_features, cv\n",
    "    \n",
    "    else:\n",
    "        # TF-IDF based feature representation\n",
    "\n",
    "        tfidf_vec = TfidfVectorizer(use_idf=True, max_df=0.95, ngram_range=ngr)\n",
    "        tfidf_vec.fit_transform(train_data[\"cleanedComment\"].values)\n",
    "\n",
    "        train_features = tfidf_vec.transform(train_data[\"cleanedComment\"].values)\n",
    "        test_features = tfidf_vec.transform(test_data[\"cleanedComment\"].values)\n",
    "\n",
    "        return train_features, test_features, tfidf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_predictions(model, X_test, k):\n",
    "    probs = model.predict_proba(X_test)         # get probabilities instead of labels\n",
    "    best_n = np.argsort(probs, axis=1)[:,-k:]   # get top k predictions by index (note: just index)\n",
    "\n",
    "    preds = [[model.classes_[predicted_cat] for predicted_cat in prediction] for prediction in best_n]          # get category of predictions\n",
    "    preds = [item[::-1] for item in preds]     # reverse categories, descending order of importance\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_preds(Y_test, Y_preds):\n",
    "    pred_gold_list=[[[Y_test[idx]],pred] for idx,pred in enumerate(Y_preds)]\n",
    "    return pred_gold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(eval_items:list):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for item in eval_items:\n",
    "        true_pred = item[0]\n",
    "        machine_pred = set(item[1])\n",
    "\n",
    "        for cat in true_pred:\n",
    "            if cat in machine_pred:\n",
    "                correct += 1\n",
    "    accuracy = correct/float(len(eval_items))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reciprocal_rank(true_labels:list, machine_preds:list):\n",
    "    tp_pos_list = [(idx + 1) for idx, r in enumerate(machine_preds) if r in true_labels]\n",
    "    \n",
    "    rr = 0\n",
    "    if len(tp_pos_list) > 0:\n",
    "        first_pos_list = tp_pos_list[0]\n",
    "        rr = 1 / float(first_pos_list)\n",
    "    \n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean reciprocal rank, which I understand as follows\n",
    "\"\"\" this is admittedly much more useful when dealing with multiple categories\n",
    "essentially, how many of the relevant categories appear in the top k predicted categories (or something to that effect, as it's typically shown as a percentage)\n",
    "as our data currently has two possible categories, if we let top_k=2, everything comes out to 100% lol, and if top_k=1, accuracy and mrr are the same\n",
    "\"\"\"\n",
    "\n",
    "def compute_mrr_at_k(items:list):\n",
    "    rr_total = 0\n",
    "\n",
    "    for item in items:\n",
    "        rr_at_k = _reciprocal_rank(item[0], item[1])\n",
    "        rr_total += rr_at_k\n",
    "        mrr = rr_total / 1/float(len(items))\n",
    "    \n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can tweak log reg model parameters to potentially improve accuracy, see https://levelup.gitconnected.com/regularization-in-machine-learning-59c619da4537 for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, field=\"cleanedComments\", feature_rep=\"binary\", top_k=1, ngr=(1,1)):\n",
    "    train_data, test_data = train_test_split(df, random_state=0)            # get train-test split\n",
    "    y_train = train_data[\"sentiment\"].values                                # isolate labels in training and testing data\n",
    "    y_test = test_data[\"sentiment\"].values\n",
    "\n",
    "    X_train, X_test, feature_transformer = extract_features(reviews, train_data, test_data, type=feature_rep, ngr=ngr)           # get features\n",
    "\n",
    "    # NOTE: tweak parameters (especially C and penalty) to potentially improve log reg model\n",
    "    log_reg = LogisticRegression(verbose=1, solver=\"liblinear\", random_state=0, C=0.5, penalty=\"l2\")       # create model and fit to training data\n",
    "    model = log_reg.fit(X_train, y_train)\n",
    "\n",
    "    preds = get_top_k_predictions(model, X_test, top_k)                 # get k most relevant predictions\n",
    "\n",
    "    eval_items = collect_preds(y_test, preds)                           # get predicted values and ground into list of lists (for ease of evaluation)\n",
    "\n",
    "    accuracy = compute_accuracy(eval_items)                             # get final stats on success rate of model\n",
    "    mrr_at_k = compute_mrr_at_k(eval_items)\n",
    "\n",
    "    return model, feature_transformer, accuracy, mrr_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finally ready to start actually using the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLRModel(feature_rep=\"binary\", ngr=(1,1), k=1):\n",
    "    model, transformer, accuracy, mrr = train_model(reviews, \"cleanedComments\", feature_rep=feature_rep, top_k=k, ngr=ngr)\n",
    "    print(\"\\n*** USING \" + feature_rep.upper() +\" FEATURE REPRESENTATION ***\")\n",
    "    print(\"--- top \" + str(k) + \" feature(s) in n-gram range \" + str(ngr) + \" ---\")\n",
    "    print(\"Accuracy={0}; MRR={1}\".format(accuracy * 100,mrr * 100))\n",
    "    return model, transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model using every reasonable combination of feature representation, k-value, and n-gram range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING BINARY FEATURE REPRESENTATION ***\n",
      "--- top 1 feature(s) in n-gram range (1, 1) ---\n",
      "Accuracy=86.1534461378455; MRR=86.1534461378455\n"
     ]
    }
   ],
   "source": [
    "# binary rep, top 1 feature, unigram\n",
    "model, transformer = runLRModel(feature_rep=\"binary\", k=1, ngr=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING BINARY FEATURE REPRESENTATION ***\n",
      "--- top 2 feature(s) in n-gram range (1, 1) ---\n",
      "Accuracy=100.0; MRR=93.07672306892276\n"
     ]
    }
   ],
   "source": [
    "# binary rep, top 2 features, unigram\n",
    "model, transformer = runLRModel(feature_rep=\"binary\", k=2, ngr=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING BINARY FEATURE REPRESENTATION ***\n",
      "--- top 1 feature(s) in n-gram range (2, 2) ---\n",
      "Accuracy=85.39941597663908; MRR=85.39941597663908\n"
     ]
    }
   ],
   "source": [
    "# binary rep, top 1 feature, bigram\n",
    "model, transformer = runLRModel(feature_rep=\"binary\", k=1, ngr=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING BINARY FEATURE REPRESENTATION ***\n",
      "--- top 2 feature(s) in n-gram range (2, 2) ---\n",
      "Accuracy=100.0; MRR=92.69970798831953\n"
     ]
    }
   ],
   "source": [
    "# binary rep, top 2 features, bigram\n",
    "model, transformer = runLRModel(feature_rep=\"binary\", k=2, ngr=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING BINARY FEATURE REPRESENTATION ***\n",
      "--- top 1 feature(s) in n-gram range (1, 2) ---\n",
      "Accuracy=87.24948997959918; MRR=87.24948997959918\n"
     ]
    }
   ],
   "source": [
    "# binary rep, top 1 feature, unigram + bigram\n",
    "model, transformer = runLRModel(feature_rep=\"binary\", k=1, ngr=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING BINARY FEATURE REPRESENTATION ***\n",
      "--- top 2 feature(s) in n-gram range (1, 2) ---\n",
      "Accuracy=100.0; MRR=93.6247449897996\n"
     ]
    }
   ],
   "source": [
    "# binary rep, top 2 features, unigram + bigram\n",
    "model, transformer = runLRModel(feature_rep=\"binary\", k=2, ngr=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING COUNT FEATURE REPRESENTATION ***\n",
      "--- top 1 feature(s) in n-gram range (1, 1) ---\n",
      "Accuracy=86.57946317852713; MRR=86.57946317852713\n"
     ]
    }
   ],
   "source": [
    "# count rep, top 1 feature, unigram\n",
    "model, transformer = runLRModel(feature_rep=\"count\", k=1, ngr=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING COUNT FEATURE REPRESENTATION ***\n",
      "--- top 2 feature(s) in n-gram range (1, 1) ---\n",
      "Accuracy=100.0; MRR=93.28973158926357\n"
     ]
    }
   ],
   "source": [
    "# count rep, top 2 features, unigram\n",
    "model, transformer = runLRModel(feature_rep=\"count\", k=2, ngr=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING COUNT FEATURE REPRESENTATION ***\n",
      "--- top 1 feature(s) in n-gram range (2, 2) ---\n",
      "Accuracy=84.07936317452697; MRR=84.07936317452697\n"
     ]
    }
   ],
   "source": [
    "# count rep, top 1 feature, bigram\n",
    "model, transformer = runLRModel(feature_rep=\"count\", k=1, ngr=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING COUNT FEATURE REPRESENTATION ***\n",
      "--- top 2 feature(s) in n-gram range (2, 2) ---\n",
      "Accuracy=100.0; MRR=92.03968158726349\n"
     ]
    }
   ],
   "source": [
    "# count rep, top 2 features, bigram\n",
    "model, transformer = runLRModel(feature_rep=\"count\", k=2, ngr=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING COUNT FEATURE REPRESENTATION ***\n",
      "--- top 1 feature(s) in n-gram range (1, 2) ---\n",
      "Accuracy=87.4234969398776; MRR=87.4234969398776\n"
     ]
    }
   ],
   "source": [
    "# count rep, top 1 feature, unigram + bigram\n",
    "model, transformer = runLRModel(feature_rep=\"count\", k=1, ngr=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING COUNT FEATURE REPRESENTATION ***\n",
      "--- top 2 feature(s) in n-gram range (1, 2) ---\n",
      "Accuracy=100.0; MRR=93.7117484699388\n"
     ]
    }
   ],
   "source": [
    "# count rep, top 2 features, unigram + bigram\n",
    "model, transformer = runLRModel(feature_rep=\"count\", k=2, ngr=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING TFIDF FEATURE REPRESENTATION ***\n",
      "--- top 1 feature(s) in n-gram range (1, 1) ---\n",
      "Accuracy=86.57946317852713; MRR=86.57946317852713\n"
     ]
    }
   ],
   "source": [
    "# tfidf rep, top 1 feature, unigram\n",
    "model, transformer = runLRModel(feature_rep=\"tfidf\", k=1, ngr=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING TFIDF FEATURE REPRESENTATION ***\n",
      "--- top 2 feature(s) in n-gram range (1, 1) ---\n",
      "Accuracy=100.0; MRR=93.28973158926357\n"
     ]
    }
   ],
   "source": [
    "# tfidf rep, top 2 features, unigram\n",
    "model, transformer = runLRModel(feature_rep=\"tfidf\", k=2, ngr=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING TFIDF FEATURE REPRESENTATION ***\n",
      "--- top 1 feature(s) in n-gram range (2, 2) ---\n",
      "Accuracy=84.07936317452697; MRR=84.07936317452697\n"
     ]
    }
   ],
   "source": [
    "# tfidf rep, top 1 feature, bigram\n",
    "model, transformer = runLRModel(feature_rep=\"tfidf\", k=1, ngr=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING TFIDF FEATURE REPRESENTATION ***\n",
      "--- top 2 feature(s) in n-gram range (2, 2) ---\n",
      "Accuracy=100.0; MRR=92.03968158726349\n"
     ]
    }
   ],
   "source": [
    "# tfidf rep, top 2 features, bigram\n",
    "model, transformer = runLRModel(feature_rep=\"tfidf\", k=2, ngr=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING TFIDF FEATURE REPRESENTATION ***\n",
      "--- top 1 feature(s) in n-gram range (1, 2) ---\n",
      "Accuracy=87.4234969398776; MRR=87.4234969398776\n"
     ]
    }
   ],
   "source": [
    "# tfidf rep, top 1 feature, unigram + bigram\n",
    "model, transformer = runLRModel(feature_rep=\"tfidf\", k=1, ngr=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "*** USING TFIDF FEATURE REPRESENTATION ***\n",
      "--- top 2 feature(s) in n-gram range (2, 2) ---\n",
      "Accuracy=100.0; MRR=92.03968158726349\n"
     ]
    }
   ],
   "source": [
    "# tfidf rep, top 2 features, unigram + bigram\n",
    "model, transformer = runLRModel(feature_rep=\"tfidf\", k=2, ngr=(2,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed8ce2715666cca47edfe3dc40f16f58fc193b5a7b06958e2ae06c97afdf9990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
